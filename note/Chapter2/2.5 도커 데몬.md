>[!note]
>지금까지 도커를 사용하는 방법을 설명했습니다. 가장 먼저 알아야 할 컨테이너부터 시작해서 컨테이너의 밑바탕이 되는 이미지, 그리고 그 이미지를 생성할 수 있는 Dockerfile을 알아봤습니다.
>그렇다면 이제는 도커 자체를 다뤄볼 차례입니다. 도커 자체에 사용할 수 있는 여러 옵션을 익히면 컨테이너와 이미지를 좀 더 쉽게 사용할 수 있을 뿐더러 도커를 이용한 개발이 더욱 수월해질 것입니다.

# 2.5.1 도커의 구조

도커를 사용할 때 docker라는 명령어를 맨 앞에 붙여서 사용해왔습니다. 그렇다면 도커는 실제로 어디에 있는 걸까요? which 명령어로 도커 명령어의 위치를 확인할 수 있습니다.

---

```powershell
> which docker
/usr/bin/docker

# 보다시피 도커 명령어는 /usr/bin/docker에 위치한 파일을 통해 사용되고 있습니다. 이번에는 실행 중인 도커 프로세스를 확인해보겠습니다.

> tasklist | findstr docker
com.docker.backend.exe       31224 Console                    1     58,132 K    
com.docker.backend.exe       31368 Console                    1    121,444 K    
com.docker.dev-envs.exe      31736 Console                    1     13,736 K    
com.docker.build.exe         30736 Console                    1     33,744 K
# > ps aux | grep docker, in Linux
# 실행 중인 프로세스의 목록을 출력하는 명령어입니다.
# 컨테이너나 이미지를 다루는 명령어는 /usr/bin/docker에서 실행되지만, 사실 도커 엔진의 프로세스는 /usr/bin/dockerd 파일로 실행되고 있습니다.
# 현재는 windows에서 실행중이기에 com.docker.backend.exe가 도커 엔진 프로세스입니다.
# 이는 docker 명령어가 실제 도커 엔진이 아닌 클라이언트로서의 도커이기 때문입니다.
```

>[!important]
> 도커의 구조는 크게 두 가지로 나뉩니다. 하나는 `클라이언트`로서의 도커이고, 하나는 `서버`로서의 도커입니다.
> 실제로 컨테이너를 생성하고 실행하며 **이미지를 관리하는 주체**는 `도커 서버`이고, 이는 `dockerd 프로세스`로서 동작합니다.
>  
> 도커 엔진은 외부에서 `API 입력`을 받아 도커 엔진의 기능을 수행하는데, 도커 프로세스가 실행되어 서버로서 입력을 받을 준비가 된 상태를 `도커 데몬`이라고 이야기합니다.
> 
> 다른 하나는 도커 클라이언트입니다. 도커 데몬은 API 입력을 받아 도커 엔진의 기능을 수행하는데, 이 API를 사용할 수 있도록 CLI를 제공하는 것이 도커 클라이언트입니다. 
> 사용자가 `docker로 시작하는 명령어`를 입력하면 도커 클라이언트를 사용하는 것이며, 도커 클라이언트는 입력된 명령어를 `로컬에 존재하는 도커 데몬`에게 **API로서 전달**합니다. 이때 도커 클라이언트는 `/var/run/docker.sock`에 위치한 `유닉스 소켓`을 통해 도커 데몬의 API를 호출합니다.
> 
> 도커 클라이언트가 사용하는 유닉스 소켓은 같은 호스트 내에 있는 도커 데몬에게 명령을 전달할 때 사용됩니다. tcp로 원격에 있는 도커 데몬을 제어하는 방법도 있지만 이는 뒤에서 자세히 설명하겠습니다.

![그림 2.61](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb5CU07%2Fbtrh0ElJHJ1%2F8wRlg0MqKOpJvNL7xqhg21%2Fimg.jpg)

>[!summary]
>즉, `터미널`이나 `PuTTY` 등으로 도커가 설치된 호스트에 접속해 `docker 명령어`를 입력하면 **아래와 같은 과정**으로 도커가 제어됩니다.
>
>1. 사용자가 `docker version` 같은 **도커 명령어**를 입력합니다.
>2. `/usr/bin/docker` 는 `/var/run/docker.sock` **유닉스 소켓**을 사용해 도커 데몬에게 명령어를 전달합니다.
>3. 도커 데몬은 이 명령어를 파싱하고 명령어에 해당하는 작업을 수행합니다.
>4. 수행 결과를 도커 클라이언트에게 반환하고 사용자에게 결과를 출력합니다.
>   
>이것은 아무런 설정을 하지 않았을 때 일반적으로 도커 데몬을 제어하는 순서입니다. 도커 데몬에 각종 옵션을 추가해 실행한다면 위 순서에 별도의 과정이 포함될 수 있습니다.

>[!warning]
>Windows 환경에서 Docker를 설치하면, **유닉스 기반의 `/var/run/docker.sock` 소켓을 사용하지 않는 대신**, Docker는 Windows에서 `Windows 네이티브 방식`으로 동작하며, `named pipe`를 사용하여 도커 데몬과 통신합니다.
>
>Windows에서 Docker는 일반적으로 `\\.\pipe\docker_engine` 이라는 **네임드 파이프를 사용**합니다. 이 파이프는 Docker CLI가 도커 데몬과 통신하는 데 사용되며, 이는 유닉스 소켓과 유사한 역할을 합니다.

# 2.5.2 도커 데몬 실행

도커 데몬은 일반적으로 아래와 같은 명령어로 시작, 정지할 수 있습니다. 우분투에서 도커가 설치되면 자동으로 서비스로 등록되므로 호스트가 재시작하더라도 자동으로 실행됩니다.

---

```powershell
> service docker start
> service docker stop
# in Unix

> net start com.docker.service
> net stop com.docker.service
# in Windows
# 실제로 해본 결과 Docker Desktop의 Docker Engine 버전은 27.5.1로 해당 명령어는 도커 클라이언트인 Docker Desktop Service 서비스를 아래 문구와 함께 시작했습니다.
# Docker Desktop Service 서비스가 잘 시작되었습니다.
# 이후 보인 tasklist | findstr docker 명령어에선 com.docker.services가 실행되고 있었음.
# 제가 보기에 서비스 시작이 아닌 Console 앱인 com.docker.backend.exe와 com.docker.dev-envs.exe가 실행되고 있어야 도커 데몬이 정상작동 하는 듯 합니다.

# 파일을 찾아본 결과 C:\Program Files\Docker\Docker\resources\com.docker.backend.exe
# 콘솔 앱을 실행시킨 경우, Windows에서 도커 데몬이 실행됩니다. 따라서 dockerd 역할을 해당 콘솔 앱 파일이 대체하고 있습니다. 이 경우 도커 데몬이 Foreground에서 돌아가게 됩니다.

> systemctl enable docker
# in 레드햇 계열
# 레드햇 계열의 OS는 도커를 설치해도 자동으로 실행되도록 설정되지는 않습니다. 도커를 자동으로 실행하도록 설정하려면 아래의 명령어로 docker 서비스를 활성화합니다.
```

>[!note]
>앞에서 설명했듯이 도커 서비스는 **dockerd로 도커 데몬을 실행**합니다. 그러나 서비스를 사용하지 않고 직접 도커 데몬을 실행할 수도 있습니다. 도커 서비스를 정지한 뒤 명령어로 도커를 직접 실행해 봅시다. **`dockerd` 명령어** 또한 `/usr/bin/dockerd` 로서 존재하기 때문에 docker 명령어와 같이 바로 사용할 수 있습니다.
>
>```powershell
>> service docker stop
>> dockerd 
># in Unix
>
>> C:\Program Files\Docker\Docker\resources\com.docker.backend.exe
># in Windows, in 27.5.1 Docker engine version
>```
>
>dockerd를 입력하면 도커 데몬이 실행됩니다. 그럼 도커 데몬에 대한 각종 정보가 출력되는데 마지막에 **유닉스 소켓(/var/run/docker.sock)에서 입력(listen)을 받을 수 있는 상태라는 메세지**가 출력됩니다. 터미널을 하나 더 연 다음 도커 명령어를 입력하면 이전처럼 도커를 사용할 수 있습니다.

# 2.5.3 도커 데몬 설정 in Unix OS

지금까지 도커 데몬과 도커 클라이언트가 어떻게 구성돼 있는지 살펴봤습니다. 그렇다면 도커 데몬에 적용할 수 있는 옵션으로는 무엇이 있는지 `dockerd --help` 확인해보겠습니다.

>[!warning]
>Windows OS의 경우, Docker 데몬은 Docker Desktop에 의해서 관리되기 때문에, WSL2 통합 설정을 마쳐도 WSL2에서는 `dockerd` 명령어를 사용할 수 없습니다.
>
>만약 도커 데몬 설정을 하려면 Docker Desktop에서 Docker Engine 탭의 **설정 파일**을 통해 가능합니다. 

---

![dockerd --help](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F5hk4R%2Fbtq9ylWNxxV%2FfnoerEFT3TzmkG3VzTOKq1%2Fimg.png)

도커 데몬에 적용할 수 있는 옵션은 매우 많습니다. --help의 출력 결과를 자세히 살펴보면 레지스트리 컨테이너를 구축할 때 사용했던 --insecure-registry도 있고, 컨테이너의 로깅을 설정할 때 사용했던 --log-driver, 스토리지 백엔드를 변경할 때 사용하는 --storage-opt도 있습니다.

그러나 이전 절의 마지막에서 설명했던 바와 같이 dockerd 명령어로 도커 데몬을 직접 실행하는 것보다 도커 설정 파일을 수정한 뒤 도커 데몬이 설정 파일을 읽어 서비스로 실행되게 하는 것이 일반적입니다.

이번 절에서는 도커 데몬의 옵션을 설명하기 위해 dockerd 명령어로 예를 들지만 실제로 사용할 때는 옵션을 그대로 설정 파일의 DOCKER_OPTS에 입력하면 됩니다.

```Powershell

예를 들어, 다음의 두 방식은 동일하게 도커 데몬을 설정하며, 직접 도커 데몬을 실행하느냐 또는 서비스로 실행하느냐의 차이만 있습니다. 다음 명령어는 dockerd로 직접 도커 데몬을 실행합니다.

> dockerd -H tcp://0.0.0.0:2375 --insecure-registry=192.168.100.99:5000 --tls=false

아래 예제의 설정 파일인 /etc/default/docker는 우분투 14.04에서 도커를 실행하는 경우의 설정 파일입니다. docker라는 이름의 서비스가 이 파일을 읽어 도커 데몬을 서비스로서 실행합니다.
```

```/etc/default/docker
...
DOCKER_OPTS="dockerd -H tcp://0.0.0.0:2375 --insecure-registry=192.168.100.99:5000 --tls=false"
```

>[!note]
>도커 데몬의 설정 옵션은 매우 많으며 주요 옵션에 대해서만 공부할 예정입니다.

## 2.5.3.1 도커 데몬 제어: -H

`-H` 옵션은 도커 데몬의 API를 사용할 수 있는 방법을 추가합니다. 아무런 옵션을 설정하지 않고 도커 데몬을 실행하면 **도커 클라이언트**인 `/usr/bin/docker`를 위한 **유닉스 소켓**인 `/var/run/docker.sock`을 사용합니다. 그러므로 단순히 `dockerd`를 실행해 도커 데몬을 실행해도 **도커 클라이언트 CLI**를 사용할 수 있습니다. 즉, 다음의 두 명령어는 차이가 없습니다.

```Powershell
> dockerd
> dockerd -H unix:///var/run/docker.sock
```

-H에 `IP 주소`와 `포트 번호`를 입력하면 원격 API인 **Docker Remote API**로 도커를 제어할 수 있습니다. Remote API는 도커 클라이언트와 다르게 ==로컬에 있는 도커 데몬이 아니더라도== 제어할 수 있으며, **RESTful API**형식을 띠고 있으므로 HTTP 요청으로 도커를 제어할 수 있습니다.

다음과 같이 도커 데몬을 실행하면 호스트에 존재하는 모든 네트워크 인터페이스의 IP 주소와 2375번 포트를 바인딩해 입력을 받습니다.

```Powershell
> dockerd -H tcp://0.0.0.0:2375
```

>[!warning]
>-H에 unix:///var/run/docker.sock를 지정하지 않고, 위와 같이 Remote API만을 위한 바인딩 주소를 입력했다면 유닉스 소켓은 비활성화되므로 도커 클라이언트를 사용할 수 없게 되며, docker로 시작하는 명령어를 사용할 수 없습니다.
>
>따라서 일반적으로 도커 클라이언트를 위한 유닉스 소켓과 Remote API를 위한 바인딩 주소를 동시에 설정합니다.
>
>```Powershell
>> dockerd -H unix:///var/run/docker.sock -H tcp://0.0.0.0:2375
>```

도커 클라이언트가 도커 데몬에게 명령어를 수행하도록 요청할 때도 내부적으로 같은 API를 사용하므로 Remote API 또한 도커 클라이언트에서 사용 가능한 모든 명령어를 사용할 수 있습니다. -H로 Remote API를 사용하려면 cURL 같은 HTTP 요청 도구를 사용합니다. 
예를 들어, IP 주소가 192.168.99.100인 도커 호스트에서 -H로 Remote API를 허용했다면 다른 호스트에서 다음과 같이 Remote API를 사용할 수 있습니다.

```
root@docker-daemon:/# dockerd -H tcp://192.168.99.100:2375
...
INFO[2025-02-06T16:15:31.35496870+09:00] API listen on 192.168.99.100:2375
```

```
root@client:/# curl 192.168.99.100:2375/version --silent | python -m json.tool

192.168.99.100:2375/version으로 HTTP 요청을 전송하는 것은 docker version이라는 명령어와 같습니다.

Remote API의 종류는 도커 명령어의 개수만큼 있으며, API에 따라서 사용하는 방법이 도커 명령어와 조금씩 다른 부분도 있으므로 HTTP 도구로 직접 API 요청을 전송하기보다는 특정 언어로 바인딩된 라이브러리를 사용하는 것이 일반적입니다. 뒤에서 자세히 설명하겠지만 Remote API를 특정 언어의 라이브러리로 사용하면 Remote API를 사용하기 위해 일일이 HTTP 요청을 사용할 필요도 없고, 도커를 활용할 수 있는 다양한 전략을 세울 수도 있습니다.
```

![그림 2.63](https://user-images.githubusercontent.com/4648244/135513828-f4a8afb1-8e0e-4683-996f-f05d9646ecab.png)

>[!note]
>셸의 환경변수를 설정해 원격에 있는 도커를 제어할 수도 있습니다.  도커 클라이언트는 셸의 DOCKER_HOST 변수가 설정돼 있다면 해당 도커 데몬에 API 요청을 전달합니다. 다음 예시는 192.168.99.100:2375의 주소에 연결해 도커 데몬을 제어합니다.
>```
>root@docker-remote-client:/# export DOCKER_HOST="tcp://192.168.99.100:2375"
>root@docker-remote-client:/# docker version
>...
>```
>
>또는 도커 클라이언트에 -H 옵션을 설정해 제어할 원격 도커 데몬을 설정할 수 있습니다. 하지 않을 경우 로컬에 있는 도커 데몬을 제어합니다.

>[!tip]
>만약 Windows 환경에서 도커 데몬을 Docker Desktop에 의해서 관리하고 있는 경우 WSL2 통합을 거친 다음, **SSH 연결**을 통해서 도커 Remote가 가능하다.
>
>SSH 연결은 기본적으로 22번 포트를 사용하고 있고, 만약 포트 설정을 바꾸기 위해서는 아래 파일에서 수정을 하면 된다.
>```
>sudo vim /etc/ssh/sshd_config
>```
>
>다음 원격 클라이언트에서 `ssh [사용자 ID]@[Docker Desktop Host IP]` 명령어를 통해 접근이 가능하다.


## 2.5.3.2 도커 데몬에 보안 적용: --tlsverify

도커를 설치하면 기본적으로 보안 연결이 설정돼 있지 않습니다. 이는 도커 클라이언트, Remote API를 사용할 때 별도의 보안이 적용되지 않음을 의미합니다. 그러나 실제 운영 환경에서 도커를 사용해야 한다면 ==보안을 적용하지 않는 것은 바람직하지 않습니다.== 보안이 적용돼 있지 않으면 Remote API를 위해 바인딩된 IP 주소와 포트 번호만 알면 도커를 제어할 수 있기 때문입니다. 

이번에는 도커 데몬에 TLS 보안을 적용하고, 도커 클라이언트와 Remote API 클라이언트가 인증되지 않으면 도커 데몬을 제어할 수 없도록 설정하는 방법을 설명하겠습니다.

---

![그림 2.64](https://postfiles.pstatic.net/20160622_211/alice_k106_14665947053509lgYO_PNG/%B1%D7%B8%B22.png?type=w2)

보안을 적용할 때 사용될 파일은 총 5개로서, ca.pem, server-cert.pem, server-key.pem, cert.pem, key.pem입니다. 그림 2.64와 같이 클라이언트 측에서 도커 데몬에 접근하려면 ca.pem, cert.pem, key.pem 파일이 필요합니다.

### 인증서 파일 생성 과정 

1. 서버 측 파일 생성
	1. 인증서에서 사용될 키를 생성
		`mkdir keys && cd keys`
		`openssl genrsa -aes256 -out ca-key.pem 4096`
	2. 공용 키를 생성. 입력하는 모든 항목은 공백으로 둬도 상관 없음.
	   `openssl req -new -x509 -dyas 10000 -key ca-key.pem -sha256 -out ca.pem`
	3. 서버 측에서 사용할 키를 생성.
	   `openssl genrsa -out server-key.pem 4096`
	4. 서버 측에서 사용될 인증서를 위한 인증 요청서 파일을 생성. $HOST 부분에는 사용 중인 도커 호스트의 IP 주소 또는 도메인 이름을 입력하며, 이는 외부에서 접근 가능한 IP 주소 또는 도메인 이름이어야 함.
	   `openssl req -subj "/CN=$HOST" -sha256 -new -key server-key.pem -out server.csr`
	5. 접속에 사용될 IP 주소를 extfile.cnf 파일로 저장. 위와 마찬가지로 $HOST에는 도커 호스트의 IP 주소 또는 도메인 이름을 입력.
	   `echo subjectAltName = IP:$HOST,IP:127.0.0.1 > extfile.cnf`
	6. 다음 명령을 입력해 서버 측의 인증서 파일을 생성. 다음 예에서는 192.168.99.100으로 접속하는 연결에 사용되는 인증서 파일이 생성됨.
	   `openssl x509 -req -days 365 -sha256 -in server.csr -CA ca.pem -CAkey ca-key.pem -CAcreateserial -out server-cert.pem -extfile extfile.cnf`
	   
2. 클라이언트 측에서 사용할 파일 생성
	1. 클라이언트 측의 키 파일과 인증 요청 파일을 생성하고, extfile.cnf 파일에 extendedKeyUsage 항목을 추가.
	   `openssl genrsa -out key.pem 4096`
	2. 다음 명령을 입력해 클라이언트 측의 인증서를 생성.
	   `openssl x509 -req -days 30000 -sha256 -in client.csr -CA ca.pem ca-key.pem -CAcreateserial -out cert.pem -extfile extfile.cnf`
	3. 여기까지 따라 했으면 앞에서 말한 것처럼 5개의 파일이 모두 만들어졌는지 확인.
	4. 생성된 파일의 쓰기 권한을 삭제해 읽기 전용 파일로 만들기.
	   `chmod -v 0400 ca-key.pem key.pem server-key.pem ca.pem server-cert.pem cert.pem`
	5. 도커 데몬의 설정 파일이 존재하는 디렉터리인 ~/.docker 로 도커 데몬 측에서 필요한 파일을 옮기기. 이것은 필수적이지는 않지만 도커 데몬에 필요한 파일을 한 곳에 모아두면 관리하기 쉬움.
	   `cp {ca,server-cert,server-key,cert,key}.pem ~/.docker`

---

보안 적용을 위한 파일을 모두 생성했으므로 다음 명령어를 입력해 암호화가 적용된 도커 데몬을 실행합니다. TLS 보안 적용을 활성화하기 위해 `-tlsverify` 옵션을 추가하고, `--tlscacert`, `--tlscert`, `--tlskey`에는 각각 보안을 적용하는 데 필요한 파일의 위치를 입력합니다. 

### 도커 데몬 TLS 보안 설정

```bash
> dockerd --tlsverify \
> --tlscacert=/root/.docker/ca.pem \
> --tlscert=/root/.docker/server-cert.pem \
> --tlskey=/root/.docker/server-key.pem \
> -H=0.0.0.0:2376 \
> -H unix:///var/run/docker.sock
```

>[!note]
>도커의 Remote API를 사용하는 포트는 **보안이 적용돼 있지 않다면** `2375번` 포트를, **보안이 적용돼 있다면** `2376번` 포트를 사용하도록 설정합니다. 이는 반드시 지켜야 할 규칙은 아니지만 도커 커뮤니티 내에서 약속한 **관례**입니다.
>

### 도커 TLS 보안 적용 연결

```bash
> docker -H 192.168.99.100:2376 \
> --tlscacert=/root/.dockeer/ca.pem \
> --tlscert=/root/.docker/cert.pem \
> --tlskey=/root/.docker/key.pem \
> --tlsverify version
...
이후에 docker info가 출력된다
```

---

인증이 정상적으로이뤄졌고, 도커 클라이언트로 원격 제어가 정상적으로 수행된 것을 알 수 있습니다. 그러나 매번 도커 명령어를 입력할 때마다 위와 같이 인증 관련 옵션을 입력하는 것은 귀찮은 일입니다. 이 또한 인증 관련 환경 변수를 설정해 매번 파일의 위치를 입력하지 않게 설정할 수 있습니다.

```bash
> export DOCKER_CERT_PATH="/root/.docker"
> export DOCKER_TLS_VERIFY=1

> docker -H 192.168.99.100:2376 version
...
이후에 docker info가 출력된다.
```

>[!tip]
>셸의 환경 변수는 셸이 종료되면 초기화되므로 ~/.bashrc 등의 파일에 export를 추가해 셸을 사용할 때마다 환경 변수의 값을 설정할 수 있습니다.
>```
>> vi ~/.bashrc
>...
>export DOCKER_CERT_PATH="/root/.docker"
>export DOCKER_TLS_VERIFY=1
>... 
>```

>[!note]
>curl로 보안이 적용된 도커 데몬의 Remote API를 사용하려면 다음과 같이 플래그를 추가해 사용 가능합니다.
>```
>> curl https://192.168.99.100:2376/version \
>> --cert ~/.docker/cert.pem \
>> --key ~/.docker/key.pem
>> --cacert ~/.docker/ca.pem
>```  

>[!important]
>만약 Docker Desktop으로 도커 데몬에 TLS 보안 인증 설정을 추가할 경우, 위에서 생성한 5가지 파일에 대해서 아래와 같이 도커 데몬 JSON 설정 파일을 수정해주면 됩니다.
>```
>{
>  "builder": {
>    "gc": {
>      "defaultKeepStorage": "20GB",
>      "enabled": true
>    }
>  },
>  "experimental": false,
>  "tls": true,
>  "tlsverify": true,
>  "tlscacert": "/path/to/ca.pem",
>  "tlscert": "/path/to/server-cert.pem",
>  "tlskey": "/path/to/server-key.pem",
>  "hosts": ["tcp://0.0.0.0:2376", "unix:///var/run/docker.sock"]
>}
>```


## 2.5.3.3 도커 스토리지 드라이버 변경: --storage-driver

도커는 특정 스토리지 백엔드 기술을 사용해 도커 컨테이너와 이미지를 저장하고 관리합니다. 
일부 운영체제는 도커를 설치할 때 기본적으로 사용하도록 설정된 스토리지 드라이버가 있는데, 우분투같은 데비안 계열 운영체제는 overlay2를, 구 버전의 CentOS와 같은 운영체제는 devicemapper를 사용하는 것이 대표적인 예입니다.

```bash
이는 docker info 명령어로 확인할 수 있습니다.

> docker info | grep "Storage Driver"
Storage Driver: overlayfs

overlayfs는 overlay2의 개선된 버전입니다.
```

도커를 사용하는 환경에 따라 스토리지 드라이버는 자동으로 정해지지만 도커 데몬 실행 옵션에서 스토리지 드라이버를 ==변경할 수도 있습니다.== 스토리지 드라이버는 `--storage-driver` 옵션을 사용해 선택할 수 있으며, 지원되는 드라이버로는 `overlayfs`, `aufs`, `btrfs`, `devicemapper`, `vfs`, `zfs` 등이 있습니다. 

```bash
> dockerd --storage-driver=devicemapper
```

>[!note]
>도커 데몬이 사용하는 컨테이너와 이미지가 저장되는 디렉토리를 별도로 지정하지 않았다면 드라이버별로 사용되는 컨테이너와 이미지는 `/var/lib/docker/{드라이버 이름}`에 저장됩니다.
>컨테이너와 이미지 파일이 저장될 디렉터리를 임의로 지정하려면 `--data-root` 옵션을 사용합니다. 빈 디렉터리를 `--data-root` 옵션의 입력으로 설정하면 도커 엔진이 초기화된 상태로 도커 데몬이 실행됩니다.
>
>```
>> dockerd --data-root /DATA/docker
>```
>
>단, 여러 개의 디바이스 드라이버의 디렉터리가 하나의 디렉터리에 존재할 경우 --storage-driver 옵션으로 사용할 드라이버를 명시하지 않으면 도커 데몬이 어느 드라이버를 사용할지 찾지 못하는 상황이 발생해 도커 데몬이 실행되지 않을 수 있습니다.

>[!important]
>만약 Docker Desktop으로 도커 데몬에 스토리지 드라이버를 설정해야 한다면 아래와 같이 도커 데몬 JSON 설정 파일에서 storage-driver 키 값을 수정해주면 된다.
>
>`overlay2` 외에도 `aufs`, `btrfs`, `devicemapper` 등 다른 스토리지 드라이버를 사용할 수 있으며, 선택하는 드라이버는 시스템 환경에 따라 달라질 수 있습니다.
>
>```
>{
>  "builder": {
>    "gc": {
>      "defaultKeepStorage": "20GB",
>      "enabled": true
>    }
>  },
>  "experimental": false,
>  "storage-driver": "overlay2"
>}
>```

---
### 스토리지 드라이버의 원리

이미지는 읽기 전용 파일로 사용되며 컨테이너는 이 이미지 위에 얇은 컨테이너 레이어를 생성함으로써 컨테이너의 고유한 공간을 생성한다는 것이었습니다.

그러나 이것은 기본적인 개념이고, 실제로 컨테이너 내부에서 ==읽기와 새로운 파일 쓰기, 기존의 파일 쓰기 작업이 일어날 때==는 드라이버에 따라 `Copy-on-Write(CoW)` 또는 `Redirect-on-Write(RoW)` 개념을 사용합니다. 

스냅숏의 기본 개념은 '원본 파일은 **읽기 전용**으로 사용하되 ==이 파일이 변경되면 새로운 공간을 할당한다=='입니다. 스토리지를 스냅숏으로 만들면 스냅숏 안에 어느 파일이 어디에 저장돼 있는지가 목록으로 저장됩니다. 그리고 이 스냅숏을 사용하다가 스냅숏 안의 파일에 변화가 생기면 변경된 내역을 따로 관리함으로써 스냅숏을 사용합니다.

![그림 2.65](https://user-images.githubusercontent.com/47745785/121154990-5f978000-c882-11eb-9cfb-3a2f1d9c87e5.png)

예를 들어, 그림 2.65에서 A, B, C 파일이 스냅숏으로 생성됐다면 이 파일에 읽기 작업을 수행하는 애플리케이션은 단순히 파일시스템의 원본 파일에 접근해 파일 내용을 읽으면 됩니다. 
그러나 애플리케이션이 스냅숏의 A 파일에 쓰기 작업을 수행해야 할 경우에는 조금 상황이 달라집니다. 원본 파일을 유지하면서도 변경된 사항을 저장할 수 있어야 하기 때문입니다. 이를 해결하는 방법에 따라 `CoW`, `RoW`로 나뉩니다.

![그림 2.66](https://user-images.githubusercontent.com/47745785/121155914-30354300-c883-11eb-8980-161eac059026.png)

`CoW`는 스냅숏의 파일에 쓰기 작업을 수행할 때 ==스냅숏 공간에 원본 파일을 복사한 뒤 쓰기 요청을 반영==합니다. 이 과정에서 복사하기 위해 파일을 읽는 작업 한 번, 파일을 스냅숏 공간에 쓰고 변경사항을 쓰는 작업으로 총 2번의 쓰기 작업이 일어나므로 오버헤드가 발생합니다.

![그림 2.67](https://user-images.githubusercontent.com/47745785/121156723-ed279f80-c883-11eb-8933-54a8a7e19c34.png)

`RoW`는 `CoW`와 다르게 한 번의 쓰기 작업만 일어납니다. 이는 파일을 스냅숏 공간에 복사하는 것이 아니라 ==스냅숏에 기록된 원본 파일은 스냅숏 파일로 묶은(Freeze) 뒤 변경된 사항을 새로운 장소에 할당받아 덮어쓰는 형식==입니다.
스냅숏 파일은 그대로 사용하되, 새로운 블록은 변경 사항을호써 사용하는 것입니다.

>[!note]
>여기서는 스냅숏이라는 개념이 스냅숏 파일을 **불변(Immutable) 상태**로 유지할 수 있다는 점이 중요합니다.

![그림 2.68](https://user-images.githubusercontent.com/47745785/121157915-ecdbd400-c884-11eb-8b82-1749f921a606.png)

이를 도커 컨테이너와 이미지에 적용해 보면, 이미지 레이어는 각 스냅숏에 해당하고, 컨테이너는 이 스냅숏을 사용하는 변경점입니다. 컨테이너 레이어에는 이전 이미지에서 변경된 사항이 저장돼 있으며, 컨테이너를 이비지로 만들면 변경된 사항이 스냅샷으로 생성되고 하나의 이미지 레이어로서 존재하게 됩니다.

각 디바이스 드라이버 별로 스냅숏과 레이어를 지칭하는 용어는 조금씩 다르지만 기본적으로 이러한 개념을 따르고 있습니다.

>[!summary]
>결론적으로 도커 데몬의 드라이버들은 이런 스냅숏의 불변 상태 개념을 활용하여 `CoW`와 `RoW` 형식으로 각 이미지와 컨테이너를 관리한다고 생각하면 됩니다.

### AUFS 드라이버 사용하기

AUFS 드라이버는 데비안 계열(Ubuntu 등)에서 기본적으로 사용할 수 있는 드라이버이며, 도커에서 오랜 기간 사용해왔기 때문에 안정성 측면에서 우수하다고 평가받습니다. 그러나 `AUFS 모듈은 기본적으로 커널에 포함돼 있지 않으므로` 일부 운영체제에서는 사용할 수 없으며, 사용할 수 없는 대표적인 운영체제는 RHEL, CentOS 등입니다.

![그림 2.69](https://velog.velcdn.com/images/bbkyoo/post/b37c6b66-83e4-49fa-a1fe-4dab02686803/image.png)

AUFS 드라이버는 지금까지 설명한 이미지의 구조와 유사합니다. ==여러 개의 이미지 레이어를 유니언 마운트 지점(Union Mount Point)으로 제공하며, 컨테이너 레이어는 여기에 마운트해서 이미지를 읽기 전용으로 사용==합니다. **유니언 마운트 지점**은 `/var/lib/docker/aufs/mnt`에, **컨테이너 레이어**는 `/var/lib/docker/aufs/diff`에 존재합니다.

`AUFS` 드라이버는 컨테이너에서 읽기 전용으로 사용하는 파일을 변경해야 한다면 컨테이너 레이어로 전체 파일을 복사하고, 이 파일을 변경함으로써 변경사항을 반영합니다. 

- 복사할 파일을 찾기 위해 이미지의 가장 위의 레이어부터 시작해 아래 레이어까지 찾기 때문에 크기가 큰 파일이 이미지의 아래쪽에 있다면 시간이 더 오래 걸리는 특징이 있습니다. 
- 그러나 한 번 파일이 컨테이너 레이어로 복사되고 나면 그 뒤로는 이 파일로 쓰기 작업을 수행합니다.
- 컨테이너의 실행, 삭제 등의 컨테이너 관련 수행 작업이 매우 빠르므로 PaaS에 적합한 드라이버로 꼽히곤 합니다.

---
### Devicemapper 드라이버 사용하기

`Devicemapper` 드라이버는  레드햇 계을의 리눅스 배포판을 위해 개발된 스토리지 드라이버입니다. 따라서 CentOS를 포함한 대부분의 리눅스 배포판에서 보편적으로 Devicemapper를 사용할 수 있다는 장점이 있지만, 성능상의 이유로 deprecated된 스토리지 드라이버입니다.

>[!note]
>레드햇 계열의 리눅스는 도커 엔진 1.13.0 버전 이전에는 Devicemapper를, 이후에서는 OverlayFS를 기본적으로 사용하도록 설정돼 있습니다. 또는 OverlayFS의 사용이 불가능한 일부 CentOS 배포판에서는 Devicemapper를 기본적으로 사용하도록 설정됩니다.

해당 스토리지 드라이버는 `/var/lib/docker/devicemapper/devicemapper` 디렉토리에 100GB(설정에 따라 가변)의 `data`와 `metadata`라는 파일로써 이미지와 컨테이너를 관리합니다.
이는 도커가 100GB를 전체 사용하는 것이 아니며, 100GB의 희소 파일(sparse file)에서 공간을 할당받아 이미지와 컨테이너 레이어를 저장하는 것입니다.

이는 ==이미지와 컨테이너의 데이터가 분리된 디렉터리로 저장되는 것이 아닌 data 파일로 이뤄진 풀(pool)에서 블록 단위로 할당받는 구조==입니다. 컨테이너와 이미지 블록의 정보는 metadata 파일에 저장됩니다.

![그림 2.70](https://velog.velcdn.com/images/bbkyoo/post/a5250389-490e-4e5e-ba5c-d3c48485b852/image.png)

Devicemapper 드라이버를 사용하는 도커는 위 그림과 같이 스토리지 풀에서 공간을 할당받고, 이미지의 스냅숏을 만들어 상위 레이어를 생성합니다. ==이미지로부터 변경된 사항을 저장하는 컨테이너 레이어는 이 레이어를들을 묶은 마운트 포인트 포인트에서 새로운 스냅숏을 생성해서 사용==됩니다.

Devicemapper 드라이버를 사용하는 컨테이너는 `allocate-on-demand` 라는 원리로 컨테이너 내부에서 새로운 파일을 기록합니다. 이는 devicemapper의 pool에서 필요한 만큼의 64KB 크기의 블록 개수를 할당해서 쓰기 작업을 수행하는 것입니다. 
컨테이너 내부에 이미 존재하는, 즉 이미지에 존재하던 데이터에 쓰기 작업을 수행할 때는 변경하려는 **원본 파일의 블록을 컨테이너에 복사한 뒤, 컨테이너 내부에서 복사된 블록 파일을 수정**합니다.

>[!summary]
>이는 AUFS 드라이버와 달리 **전체 파일을 복사하지 않는다는 점에서 성능상의 이점**이 있지만 devicemapper는 컨테이너 관련 작업은 빠른 편이 아닙니다.

>[!warning]
>Devicemapper 드라이버는 데이터 풀 안에 컨테이너와 이미지 데이터를 저장하기 때문에 멀티테넌시(Multitenancy) 환경을 위해 **각 컨테이너와 이미지를 분리해 관리하는 것이 불가능**합니다.
>`PaaS` 환경에서는 여러 사용자가 다양한 컨테이너를 실행하게 되며, 각각의 컨테이너는 서로 독립적으로 관리되고 격리되어야 합니다.
>`Devicemapper`는 이러한 격리를 제공하는데 제약이 있기 때문에, 실제 운영 환경에서 `PaaS`와 같은 용도로 사용하는 것을 권장하지 않는 추세이며, 굳이 사용하고 싶다면 devicemapper의 스토리지 풀로 `loop-lvm`이 아닌 `direct-lvm`을 사용하는 것이 좋습니다.

---

### OverlayFS 드라이버 사용하기

OverlayFS는 레드햇 계열 및 라즈비안(Rasbian), 우분투 등 대부분의 운영체제에서 도커를 설치하면 자동으로 사용되도록 설정되는 드라이버입니다. OverlayFS는 AUFS와 비슷한 원리로 동작하지만 좀 더 간단한 구조로 사용되며 성능 또한 좀 더 좋기 때문에 최신 버전의 도커는 OverlayFS를 기본적으로 사용하고 있습니다.

OverlayFS 드라이버는 overlay와 overlay2 드라이버로 나뉩니다. overlay는 커널 3.18 버전 이상부터 기본적으로 내장돼 있으며, overlay2는 4.0 버전 이상에서 사용 가능합니다. overlay2는 overlay에 비해 성능이 좀 더 우수하며, 이미지를 구성하기 위해 여러 개의 레이어 구조를 지원합니다. 따라서 가능하다면 overlay2 스토리지 드라이버를 사용하는 것이 권장됩니다.

overlay 드라이버를 사용하도록 설정하면 도커 엔진이 초기화되므로 새로운 이미지를 내려받은 뒤 컨테이너를 생성해 보겠습니다. 생성된 컨테이너에서는 적당한 파일을 새로 생성해 이미지로부터 변경 사항을 만듭니다.

```bash
> docker pull ubuntu:14.04
> docker run -it --name container ubuntu:14.04
```

호스트로 빠져나와 /var/lib/docker/overlay 디렉터리의 내용을 살펴보면 컨테이너와 이미지의 파일을 담고 있는 디렉터리가 존재하는 것을 알 수 있습니다. 이 가운데 이름 끝에 -init이 붙은 디렉터리가 방금 생성한 컨테이너를 의미합니다. 이 디렉터리의 이름에서 -init을 제외한 디렉터리가 실제 컨테이너의 파일시스템을 담고 있는 디렉터리입니다.

`-init`을 제외한 이름의 디렉터리를 확인해보면 다음과 같이 4개의 파일(`lower-id`, `merged`, `upper`, `work`)이 존재합니다.

![그림 2.71](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Feq5uo7%2Fbtq9GmNMQeS%2Fu8fGwYZLBK6EkDIWnTX5hK%2Fimg.png)

`overlay `드라이버는 컨테이너를 사용하기 위해 도커를 `merged`, `upperdir`, `lowerdir`의 구조로 나눕니다. `lowerdir`은 도커의 이미지 레이어에 해당하고, `upperdir`은 컨테이너 레이어에 해당합니다. 다른 스토리지 드라이버와는 다르게 여러 계층의 이미지 레이어가 존재하는 것이 아니며, 여러 개의 이미지 레이어를 하나의 컨테이너 마운트 지점에서 통합해 사용합니다.

>[!note]
>`upperdir`에는 컨테이너에서 발생한 변경 사항을 담고 있으며, 위에서 생성한 컨테이너는 `overlayfile`이라는 변경 사항을 가지고 있기 때문에 `upperdir` 에는 `overlayfile`이 존재합니다. 그리고 `upperdir`은 이미지 레이어에 해당하는 `lowerdir`과 함께 마운트되어 최종적으로 컨테이너 내부에 보여지게 되고, 이것이 컨테이너 마운트 지점인 `merged`입니다.

>[!tip]
>AUFS와 유사하게 overlay는 이미지에 존재하는 파일에 쓰기 작업을 수행할 때 파일을 컨테이너 레이어인 upperdir로 복사(copy_up operation)해 사용합니다. 따라서 크기가 큰 파일에 쓰기 작업을 수행할 때는 upperdir에 복사하는 시간으로 인해 작업 수행에 지연이 생길 수 있으나, AUFS와는 다르게 ==계층화된 레이어 구조가 아니기 때문에== 복사할 파일을 찾는 과정에서는 AUFS보다 빠릅니다.

>[!summary]
>`overlay2`는 이미지 레이어 디렉토리에 `committed`, `link`, `diff` 폴더가 존재하고 있습니다. `diff`는 레이어의 contents(파일시스템)을 담고 있고, `link`는 이 레이어의 심볼링 링크를 담고 있습니다. `committed`는 커밋된 레이어의 데이터를 저장하는 공간입니다. 
>여기서 ==커밋==은 컨테이너를 실행하는 동안 발생한 변경 사항들을 하나의 새로운 이미지 레이어로 저장하는 과정을 말합니다.
>
>또한 --init이 있는 컨테이너 레이어 디렉토리에는 diff, link, work, lower, committed가 있으며 diff는 마찬가지로 파일 시스템을, work는 OverlayFS가 내부적으로 사용하는 디렉토리입니다.

>[!tip]
>overlay2에서 심볼링 링크는 파일이나 디렉토리의 위치를 참조하는 일종의 바로가기 역할을 하는 파일이라고 보시면 됩니다. 이를 통해 실제 파일이 저장된 위치와는 별개로, 다른 위치에서 해당 파일을 참조할 수 있다고 볼 수 있습니다. 이는 각 레이어가 어떤 다른 레이어에 의존하고 있는지를 추적하기 위해 사용하고 있습니다.

---

### Btrfs 드라이버 사용하기

Btrfs는 리눅스 파일시스템 중 하나로, SSD 최적화, 데이터 압축 등 다양한 기능을 제공합니다. Btrfs 드라이버는 Devicemapper나 AUFS, OverlayFS와 다르게 ==파일시스템을 별도로 구성하지 않으면 도커에서 사용할 수 없으며==, /var/lib/docker 디렉토리가 btrfs 파일시스템을 사용하는 공간에 마운트돼 있어야만 도커는 Btrfs를 스토리지 드라이버로 인식합니다. Btrfs는 리눅스 커널에 포함돼 있으므로 대부분의 리눅스 배포판에서 사용할 수 있습니다.

>[!note]
>Btrfs를 사용하기 위해 아래와 같이 부가 설치 과정이 필요 합니다.
>
>```bash
># 설치하기 전 도커 데몬이 실행 중이면 이를 정지합니다.
>> service docker stop
> 
># Btrfs를 생성하기 위한 도구를 설치합니다
>> apt-get install btrfs-tools #데비안계열
>> yum install btrfs-progs #레드햇계열
> 
># 다음 명령어로 Btrfs 스토리지 풀을 입력합니다. 다음 명령어에서는 /dev/xvdb를 입력해 해당 디바이스를 Btrfs로 만들었지만 사용하는 디바이스에 맞는 이름을 입력하길 바랍니다.
>> mkfs.btrfs -f /dev/xvdb
># 도커를 아직 설치하지 않아 /var/lib/docker 디렉토리가 없다면 이를 생성합니다.
>> mkdir /var/lib/docker
>
># 시스템이 재부팅될 떄마다 Btrfs 디바이스가 마운트되도록 설정하기 위해 /etc/fstab 파일에 다음 내용을 추가합니다. 
>> vi /etc/fstab
>> ...
>> /dev/xvdb /var/lib/docker btrfs defaults 0 0
>
># /etc/fstab 파일에 설정한 내용을 적용하기 위해 mount -a 명령어를 입력해 fstab 파일에 명시된 파일시스템을 마운트합니다. mount 명령어로 정상적으로 마운트됐는지 확인합니다.
>> mount -a
>> mount
>
># Btrfs 마운트가 완료됐으며, /var/lib/docker 디렉토리는 Btrfs 파일시스템을 사용하는 디바이스에 마운트됐습니다. 도커를 시작한 뒤 스토리지 드라이버를 확인해 봅시다.
>> service docker start
>> docker info | grep Storage
>```

![그림 2.72](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdmvCAt%2Fbtq9Cuzi9D7%2Flh1nBuk4JrkedGbEOY2HsK%2Fimg.png)

Btrfs 드라이버는 이미지와 컨테이너를 ==서브 볼륨과 스냅샷 단위로 관리==합니다. 구조 자체는 AUFS, Devicemapper 등 다른 스토리지 드라이버와 유사합니다. 이미지에서 가장 아래에 있는 베이스 레이어가 서브 볼륨이 되고, 그 위에 쌓이는 레이어가 베이스 레이어에 대한 스냅샷으로 생성됩니다. 새로운 컨테이너가 생성되면 컨테이너 레이어가 이미지의 맨 위에 있는 스냅샷으로 생성됩니다. 

>[!note]
>Btrfs는 Devicemapper와 달리 ==블록 단위가 아닌 파일 단위==로 각 레이어를 저장하기 때문에 /var/lib/docker/btrfs 디렉토리에서 이를 확인해볼 수 있습니다.
>
>Btffs 드라이버를 사용하는 컨테이너 내부에서 새로운 파일을 생성하는 것은 devicemapper와 마찬가지로 `allocate-on-demand` 작업에 의해서 일어납니다. 이미 존재하던 파일에 쓰기 작업을 수행할 때는 원본 파일을 보존하고 스냅샷에 새로운 공간을 할당하는 `RoW` 방식을 사용합니다.
>
>Btrfs는 자체적으로 ==SSD에 최적화==되어 있으며, 대체적으로 우수한 성능을 나타냅니다. 또한 리눅스에서 파일시스템이 제공하지 않는 여러 기능을 제공한다는 장점도 있습니다.

>[!warning]
>이 이후로 `zfs`와 같은 스토리지 드라이버가 더 있지만 현 공부의 목적은 파일시스템과 같은 스토리지 드라이버가 아니기 때문에 다음에 시간이 된다면 더 하도록 하겠습니다. (2025.02.21)


## 2.5.3.4 컨테이너 저장 공간 설정

컨테이너에 내부에서 사용되는 파일시스템의 크기는 도커가 사용하고 있는 스토리지 드라이버에 따라 조금씩 다릅니다. 예를 들어, 도커 엔진이 AUFS나 overlay2 등의 스토리지를 드라이버를 사용하도록 설정돼 있다면 컨테이너는 호스트와 저장 공간의 크기를 공유합니다. 

따라서 overlay2를 기본적으로 사용하는 우분투의 도커에서는 컨테이너 내부에서의 저장 공간이 호스트의 저장 공간 크기와 같습니다.

```bash
hexeong@DESKTOP-UKSBMKO:~$ docker info | grep overlayfs
WARNING: No blkio throttle.read_bps_device support
WARNING: No blkio throttle.write_bps_device support
WARNING: No blkio throttle.read_iops_device support
WARNING: No blkio throttle.write_iops_device support
WARNING: daemon is not using the default seccomp profile
 Storage Driver: overlayfs
hexeong@DESKTOP-UKSBMKO:~$ docker run -it --name ubuntu ubuntu:14.04
root@2ff95833f7a8:/# df -h
Filesystem      Size  Used Avail Use% Mounted on
overlay        1007G  9.9G  946G   2% /
tmpfs            64M     0   64M   0% /dev
tmpfs           7.8G     0  7.8G   0% /sys/fs/cgroup
shm              64M     0   64M   0% /dev/shm
/dev/sdd       1007G  9.9G  946G   2% /etc/hosts
tmpfs           7.8G     0  7.8G   0% /proc/acpi
tmpfs           7.8G     0  7.8G   0% /sys/firmware
root@2ff95833f7a8:/#
```

>[!warning]
>책에서는 devicemapper, overlay2에 대해서 컨테이너 저장 공간 설정법을 알려주고 있지만, 필자는 Windows 운영 환경에서 Docker Desktop으로 진행을 하기에 Docker Desktop에서 컨테이너 저장 공간 설정 방법만 다루고 넘어가도록 하겠습니다.

>[!warning]
>스토리지 드라이버마다 컨테이너에게 저장 공간을 할당하는 방식이 다릅니다. 그러나 스토리지 드라이버에 상관없이 컨테이너의 저장 공간을 제한하는 기능을 도커 엔진에서 자체적으로 제공하고 있지는 않습니다. 단, devicemapper, overlay2 등 일부 스토리지 드라이버에 한해서 가능합니다.

Docker Desktop에서 컨테이너가 사용하는 **디스크 공간을 관리**하려면 아래의 단계를 따라야 합니다.

#### 디스크 공간 설정 방법:

1. **Docker Desktop 실행**: Docker Desktop을 실행하고, **우측 상단의 톱니바퀴 아이콘**(Settings)으로 이동합니다.
    
2. **Settings 메뉴에서 Resources** 선택: 설정 메뉴에서 **"Resources"** 탭을 클릭해. 여기에서 CPU, 메모리, 디스크 등의 자원을 조정할 수 있습니다.
    
3. **Disk 이미지 관리**: **"Advanced"** 하위 메뉴에서 Docker Desktop이 사용하는 **디스크 이미지 크기**를 조정할 수 있는 옵션을 찾을 수 있습니다. 예를 들어, "Disk image size" 항목을 통해 Docker가 사용할 수 있는 **디스크 공간을 할당**할 수 있습니다.
    
4. **Docker 이미지 위치 변경**: 기본적으로 Docker는 컨테이너와 이미지 데이터를 로컬 시스템의 **기본 디렉토리**에 저장합니다. 이를 다른 디렉토리나 드라이브로 변경하고 싶다면, "Disk image location"에서 **디스크 이미지의 위치를 변경**할 수 있습니다. 예를 들어, 더 큰 외부 드라이브에 데이터를 저장하도록 경로를 설정하면 공간 부족 문제를 해결할 수 있습니다.
    
5. **설정 저장**: 디스크 크기나 위치를 변경한 후 **"Apply & Restart"** 버튼을 눌러 Docker Desktop을 재시작해야 변경 사항이 적용됩니다.

---

# 2.5.4 도커 데몬 모니터링

도커 데몬을 모니터링하는 데는 여러 가지 이유가 있을 수 있습니다. 많은 수의 도커 서버를 효율적으로 관리하기 위해서일 수도 있고, 도커로 컨테이너 애플리케이션을 개발하다가 문제가 생겼을 때 그 원인을 찾아내기 위해서일 수도 있으며, 도커를 PaaS로써 제공하기 위해 실시간으로 도커 데몬의 상태를 체크해야 할 수도 있습니다.

## 2.5.4.1 도커 데몬 디버그 모드

>[!tip]
>도커 데스크탑에서는 도커 엔진 JSON 설정 파일에서 `"debug" : true` 옵션을 추가해주면 됩니다.

도커 데몬에서 어떤 일이 일어나고 있는지 가장 확실하고 정확하게, 그리고 자세히 알아내는 방법은 도커 데몬을 디버그 옵션으로 실행하는 것입니다. 이렇게 하면 Remote API의 입출력뿐만 아니라 로컬 도커 클라이언트에서 오가는 모든 명령어를 로그로 출력합니다. 디버그 모드는 도커 데몬을 실행할 때 `-D` 옵션을 추가해서 사용할 수 있습니다.

```bash
> dockerd -D
...
```

>[!note]
>디버그 모드는 도커 데몬에 문제가 생겼을 때 무엇이 잘못됐는지 확인하는 가장 좋은 수단입니다. 그러나 로그에는 ==원하지 않는 정보까지 너무 많이 출력==되며, 호스트에 있는 파일을 읽거나 도커 데몬을 ==포그라운드 상태로 실행해야 한다는 단점==이 있으므로 이 방법만으로는 뭔가 조금 부족해 보입니다. 

## 2.5.4.2 events, stats, system df 명령어

### events

도커가 기본적으로 제공하는 명령어인 `events`는 도커 데몬에 어떤 일이 일어나고 있는지를 실시간 스트림 로그를 보여줍니다. 사용법은 매우 간단합니다. 다음 명령어 중 하나를 입력하면 도커 데몬이 수행한 명령어의 결과를 실시간으로 볼 수 있습니다.

```bash
> docker events
> docker system events

위 명령어들을 입력한 직후에는 어떠한 이벤트도 도커 데몬에 발생하지 않습니다. 하지만 우분투 컨테이너를 실행시킬 경우, 아래와 같은 로그가 작성됩니다.
```

```docker_events
2025-02-21T23:50:30.325754709+09:00 container create 4aea58cac6c227460d4f00cf57c231e6319338129567f299f6bd48d033562cf7 (image=nginx:healthcheck, maintainer=NGINX Docker Maintainers <docker-maint@nginx.com>, name=mystifying_stonebraker)
...
```

```docker_system_events
2025-02-21T23:51:26.088983316+09:00 container exec_create: /bin/sh -c curl -f http://localhost || exit 1 4aea58cac6c227460d4f00cf57c231e6319338129567f299f6bd48d033562cf7 (execID=7fef1bebfade85bf6a0ab89447a9a44a87127ee71df20430ae3792cba1abb20e, image=nginx:healthcheck, maintainer=NGINX Docker Maintainers <docker-maint@nginx.com>, name=mystifying_stonebraker)
...
```

이처럼 도커 데몬에서 실행되는 명령어의 결과를 로그로 출력합니다. 그러나 도커 클라이언트에서 입력하는 ==모든 명령어가 출력되는 것은 아니며==, `컨테이너 관련 명령어`, `이미지 관련 명령어`, `볼륨`, `네트워크`, `플러그인` 등에 관한 명령어의 수행 결과가 출력됩니다.
`events` 명령어는 filter 옵션을 사용해 원하는 정보만 출력하도록 설정할 수 있습니다. 출력의 종류는 container, image, volume, network, plugin, daemon으로 나뉘는데, 특정 항목에 대한 출력 결과만 보고 싶다면 --filter 'type=..'처럼 옵션을 설정하면 됩니다. 다음 예는 이미지에 관한 로그만 출력하도록 설정했으므로 이미지 관련 명령어만 출력될 것입니다.

```bash
> docker events --filter 'type=image'
2025-02-21T23:58:49.621346313+09:00 image pull ubuntu:latest (name=ubuntu, org.opencontainers.image.ref.name=ubuntu, org.opencontainers.image.version=24.04)
```

### stats

docker stats 명령어는 실행 중인 모든 컨테이너의 자원 사용량을 스트림으로 출력합니다. stats 명령어도 다음과 같이 간단히 사용할 수 있습니다.

```bash
> docker stats
CONTAINER ID   NAME                     CPU %     MEM USAGE / LIMIT     MEM %     NET I/O       BLOCK I/O   PID
4aea58cac6c2   mystifying_stonebraker   0.00%     28.52MiB / 15.54GiB   0.18%     1.57kB / 0B   0B / 0B     21

stats 명령어는 실행 중인 모든 컨테이너의 CPU, 메모리 제한 및 사용량, 네트워크 입출력(I/O), 블록 입출력(하드웨어 입출력) 정보를 출력합니다. 기본적으로 스트림 형태로 출력되며, 스트림이 아닌 한 번만 출력하는 방식으로 사용하고 싶다면 --no-stream 옵션을 추가합니다.
```

>[!tip]
>Remote API로 사용할 수 있는 stats 명령어는 도커 클라이언트에서 확인할 수 있는 자원 사용량보다 더욱 자세한 정보를 반환합니다. 도커 클라이언트는 퍼센트(%)와 대략적인 크기로만 출력되지만 Remote API는 모든 데이터를 바이트 단위로 반환하며 훨씬 자세한 항목을 포함합니다. 

