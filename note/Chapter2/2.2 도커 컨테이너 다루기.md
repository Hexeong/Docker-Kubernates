> [!NOTE]
> 도커 엔진을 설치하고 컨테이너와 이미지의 기본적인 개념을 이해했다면 도커 엔진을 사용할 준비가 끝났습니다. 이번에는 도커 컨테이너의 기초적인 사용법을 알아봅시다.

# 2.2.1 컨테이너 생성

```docker
docker -v
# docker 버젼 확인 명령어

docker pull centos7
# 도커 허브에서 공식 이미지를 다운로드 받는 명령어

docker run -i -t ubuntu:14.04
# docker 공식 이미지 중 우분투 이미지로 컨테이너를 실행
# 실행하면서 i로 표준입력 옵션과 t로 가상 터미널 옵션을 추가
# 만약 현재 우분투 이미지가 없다면 도커 허브에서 다운로드 받음

docker images
# 이미지 리스트 출력하는 명령어

docker create -i -t --name mycentos centos:7
# centos:7이라는 이미지로 mycentos라는 이름의 컨테이너를 생성하는 명령어

docker start mycentos
# mycentos라는 컨테이너를 실행시키는 명령어
# 여러 개의 컨테이너를 한번에 실행시킬 수 있다. 이는 stop과 restart에도
# 해당된다

docker attach mycentos
# mycentos라는 컨테이너 내부로 들어가는 명령어
```

# 2.2.2 컨테이너 목록 확인

```docker
docker ps
# 살아있는 컨테이너 목록을 확인하는 명령어

docker ps -a
# 죽어있는 모든 컨테이너까지 포함한 목록을 확인하는 명령어

docker inspect mycentos
# mycentos 컨테이너의 정보를 출력하는 명령어

docker inspect mycentos | grep Id
# 컨테이너의 Id를 확인하는 명령어
# Windows 환경에서는 `docker inspect mycentos | findstr "Id"` 명령어로 대체
```

# 2.2.3 컨테이너 삭제

```docker
docker rm mycentos
# mycentos라는 컨테이너를 삭제하는 명령어

docker stop mycentos
# mycentos라는 컨테이너를 삭제하기 위해서 실행중인 컨테이너를 중지시키는 명령어

docker rm -f mycentos
# 해당 컨테이너를 강제 삭제하는 명령어, 실행중이여도 삭제 됨.

docker container prune
# 모든 컨테이너를 삭제하는 명령어

docker stop $(docker ps -a -q)
docker rm $(docker ps -a -q)
# docker ps -a -q로 모든 컨테이너의 Id만을 조회한 다음 해당 Id를 가진 컨테이너들을 
# 전부 중지/삭제하는 명령어, 해당 명령어는 Linux기반으로 Windows에서는 $를 뺴야 함.
```

# 2.2.4 컨테이너를 외부에 노출

```docker
docker run -i -t --name network_test ubuntu:14.04
# ifconfig으로 우분투 환경에서 네트워크 환경을 조회할 수 있는 명령어
# 해당 명령어로 본 네트워크 환경은 도커의 NAT IP인 127.17.0.2를 할당받은 
# eth0 인터페이스와 로컬 호스트인 lo 인터페이스가 나타난다.
# 해당 인터페이스들의 IP끼리 포트 바인딩이 되어야 외부와 통신이 가능함

docker run -i -t --name mywebserver -p 80:80 ubuntu:14.04
# 해당 명령어로 mywebserver에 대해 호스트/컨테이너의 포트바인딩 설정이 가능하다. 
# 외부:내부는 80:80이다.

docker run -i -t -p 127.0.0.1:15530:80 ubuntu:14.04
# 해당 명령어처럼 IP 또한 지정해서 포트 바인딩이 가능하다
# apt-get update, apt-get install apache2 -y, service apache2 start 명령어로
# 아파치 서버를 시작해서 연결이 잘 되는지 확인해볼 수 있다.
# 만약 아파치 서버가 켜지면서 AH00558 경고 문구가 뜨는 건 도커 컨테이너 내부에서는
# IP 주소만 할당된 상태로 실행되기에 localhost라는 도메인 네임이 없어 발생하는 경고
# 문구로 무시하면 된다.

docker run -p 80:80 -p 443:443 <이미지>
# 해당 명령어처럼 -p를 여러 번 입력하여 여러 개의 포트 바인딩이 가능하다.
```

# 2.2.5 컨테이너 애프리케이션 구축

```docker
docker run -d \\
--name wordpressdb \\
-e MYSQL_ROOT_PASSWORD=password \\
-e MYSQL_DATABASE=wordpress \\
mysql:8
# mysql DB 컨테이너 생성 명령어, 환경 변수는 -e 옵션으로 넘겨줌
# windows 환경에서는 \\ 대신 `을 사용

docker run -d \\
--name wordpress \\
-e WORDPRESS_DB_HOST=mysql \\
-e WORDPRESS_DB_USER=root \\
-e WORDPRESS_DB_PASSWORD=password \\
--link wordpressdb:mysql \\
-p 15530:80 \\
wordpress
# 워드프레스 웹 서버 컨테이너를 실행하는 명령어
# windows 환경에서는 \\ 대신 `을 사용

# --link 옵션은 A 컨테이너에서 B 컨테이너로 접근하는 방법 중 가장 간단한
# 것으로 NAT로 할당 받은 내부 IP를 사용하는 것이다. 그러나 도커 엔진은
# 컨테이너 내부 IP를 순차적으로 할당하기에 매번 변경되는 컨테이너의 IP로
# 접근하기 어려운 문제가 있다. 따라서 --link 옵션은 항상 컨테이너에 별명
# 으로 접근하도록 설정한다. 위에서 생성한 워드 프레스 웹 서버 컨테이너는
# wordpressdb 컨테이너를 mysql이라는 별명을 붙여 접근하도록 했다
# 실제 wordpress 컨테이너에서 curl mysql:3306 입력하면 접근이 된다.

# 또한 --link 옵션은 컨테이너 실행 순서의 의존성도 정의해준다는 의미가 있다
# 하지만 현재 deprecated된 옵션이며 추후 삭제될 수 있다.

# 도커 브리지 네트워크를 사용하면 --link 옵션과 동일한 기능을 더욱 손쉽게
# 사용할 수 있으므로 브리지 네트워크를 사용하는 것을 권장한다.   

docker exec -i -t wordpressdb /bin/bash
# exec 명령어를 사용하면 컨테이너 내부에서 명령어를 실행한 뒤 그 결괏값을
# 반환받을 수 있습니다. -i -t 옵션을 추가해 /bin/bash를 상호 입출력이
# 가능한 형태로 exec 명령어를 사용했습니다.

# exec로 실행한 /bin/bash는 exit를 입력해도 컨테이너가 종료되지 않는데, 
# 이는 mysql 프로세스가 컨테이너 안에서 여전히 포그라운드 모드로 작동하고
# 있기 때문입니다.
```

# 2.2.6 도커 볼륨

>도커 이미지로 컨테이너를 생성하면 이미지는 읽기 전용이 되며 컨테이너의 변경 사항만 별도로 저장해서 각 컨테이너의 정보를 보존합니다.
>따라서 컨테이너를 삭제할 경우 원래 이미지에서 변경된 파일, DB 정보 등은 복구할 수 없게 됩니다.
>이를 방지하기 위해 나온 컨테이너의 데이터를 영속적(Persistent) 데이터로 활용할 수 있는 방법이 몇 가지 있습니다.
>그 중 가장 활용하기 쉬운 방법이 볼륨을 활용하는 것입니다.

## 2.2.6.1 호스트 볼륨 공유

```docker
docker run -d \\
--name wordpressdb_hostvolume \\
-e MYSQL_ROOT_PASSWORD=password \\
-e MYSQL_DATABASE=wordpress \\
-v /home/wordpress_db:/var/lib/mysql \\
mysql:8
# windows 환경에서는 \\ 대신 `을 사용
# -v 옵션을 추가해 호스트의 /home/wordpress_db 디렉토리와 컨테이너의
# /var/lib/mysql 디렉터리를 공유한다는 뜻입니다.
# 즉, [호스트의 공유 디렉터리]:[컨테이너의 공유 디렉터리] 형태입니다.

# 호스트의 공유 디렉토리가 존재하지 않아도 자동으로 이를 생성합니다.
# Windows에서는 /home 디렉토리는 존재하지 않기에 C:/Users/admin 디렉토리를
# 사용해야 한다.

# -v 옵션은 동시에 여러 개 사용이 가능하다.

# 만약 기존에 존재하는 디렉토리와 공유를 하게 될 경우 호스트의 디렉토리로
# 새로 생성된 컨테이너의 디렉토리가 덮어씌워지게 된다. (마운트한다.)

docker run -d \\
--name wordpress_hostvolume \\
-e WORDPRESS_DB_HOST=mysql \\
-e WORDPRESS_DB_USER=root \\
-e WORDPRESS_DB_PASSWORD=password \\
--link wordpressdb_hostvolume:mysql \\
-p 15530:80 \\
wordpress
```

## 2.2.6.2 볼륨 컨테이너

```docker
docker run -i -t \\
--name volume_overide \\
-v /home/wordpress_db:/home/testdir_2 \\
alicek106/volume_test

docker run -i -t \\
--name volumes_from_container \\
--volume-from volume_overide \\
ubuntu14.04
# volume_overide 컨테이너에서 볼륨을 공유받는 예제입니다.
# 컨테이너 생성시 --volumes_from 옵션을 설정하면 앞에서 생성한 
# volume_overide 컨테이너의 볼륨 디렉토리를 공유할 수 있습니다.
# 그러나 이는 직접 볼륨을 공유하는 것이 아닌 -v 옵션을 적용한 컨테이너를 
# 통해 공유하는 것입니다.
```

## 2.2.6.3 도커 볼륨

```docker
docker volume create --name myvolume
# 도커 자체에서 제공하는 볼륨 기능을 활용해 데이터를 보존하는 방식입니다.
# 해당 명령어로 도커 볼륨을 생성할 수 있습니다.
# 볼륨은 디렉토리 하나에 상응하는 단위로 도커 엔진에서 관리합니다.

# 도커 볼륨도 호스트 볼륨 공유와 마찬가지로 호스트에 저장함으로써 데이터를
# 보존하지만 파일이 실제로 어디에 저장되는지 사용자는 알 필요가 없습니다.

docker volume ls
# 해당 명령어로 생성된 볼륨을 확인합니다.

docker run -i -t --name myvolume_1 \\
-v myvolume:/root/ \\
ubuntu:14.04

root@60f31cc49256:~# ehco hello, volume! >> /root/volume
# /root 디렉토리에 hello, volume! 이라는 내용을 가진 volume이란 파일을 
# 생성했습니다. 다른 컨테이너도 myvolume 볼륨을 쓰면 볼륨을 활용한
# 디렉토리에 volume 파일이 존재할 것입니다.

docker run -i -t --name myvolume_2 \\
-v myvolume:/root/ \\
ubuntu:14.04

docker inspect --type volume myvolume
# 하지만 docker inspect 명령어를 사용하면 볼륨이 실제 어디에 저장되는지
# 알수 있습니다.
```

> 도커의 모든 명령어는 docker 접두어 다음에 container, image, volume 등을 명시함으로써 특정 구성 단위를 제어하는 명령어를 사용할 수 있습니다. 예를 들어, docker container inspect는 컨테이너의 정보를 출력합니다.

```docker
docker volume inspect myvolume
[
    {
        "CreatedAt": "2025-01-21T14:56:56Z",
        "Driver": "local",
        "Labels": null,
        "Mountpoint": "/var/lib/docker/volumes/myvolume/_data",
        "Name": "myvolume",
        "Options": null,
        "Scope": "local"
    }
]
```

> Driver는 볼륨이 쓰는 드라이버를, Label은 볼륨을 구분하는 라벨을 나타내며, Mountpoint는 해당 볼륨이 실제로 호스트의 어디에 저장됐는지를 의미합니다. 그러나 볼륨을 쓰는 사용자 입장에서 Mountpoint를 알 필요는 없습니다.

```docker
docker run -i -t --name volume_auto -v /root ubuntu:14.04
# 다음과 같이 컨테이너에서 공유할 디렉터리의 위치를 -v 옵션에 입력하면 해당 
# 디렉터리에 대한 볼륨을 자동으로 생성합니다.

docker volume prune
# 컨테이너가 사용하지 않는 모든 볼륨을 삭제하는 명령어
```

# 2.2.7 도커 네트워크

## 2.2.7.1 도커 네트워크 구조

> 도커는 컨테이너에 내부 IP를 순차적으로 할당하며, 이 IP는 컨테이너를 재시작할 때마다 변경될 수 있습니다. 이 내부 IP는 도커가 설치된 호스트, 즉 내부 망에서만 쓸 수 있는 IP이므로 `외부와 연결될 필요`가 있습니다.
> 
> 이 과정은 컨테이너를 시작할 때마다 호스트에 veth… 라는 네트워크 인터페이스를 생성함으로써 이뤄집니다. 도커는 각 컨테이너에 외부와의 네트워크를 제공하기 위해 컨테이너마다 `가상 네트워크 인터페이스`를 **호스트에 생성**하며 이 인터페이스의 이름은 `veth`로 시작합니다. 인터페이스는 사용자가 직접 생성할 필요는 없으며 컨테이너가 생성될 때 도커엔진이 자동으로 생성합니다.
> 
> - 도커가 설치된 호스트에서 `ifconfig`나 `ip addr`과 같은 명령어로 네트워크 인터페이스를 확인하면 `실행 중인 컨테이너 수`만큼 veth로 시작하는 인터페이스가 생성된 것을 알 수 있음
> - 즉 호스트의 veth와 컨테이너의 eth0이 연결되어 통신이 가능한 형태이다.
>     - veth 인터페이스뿐 아니라 docker0이라는 브리지도 존재하는데 docker0 브리지는 각 veth 인터페이스와 바인딩돼 호스트의 eth0와 이어주는 역할을 합니다.
>         - 호스트의 eth0 ↔ docker0 브리지 ↔ 호스트의 veth ↔ 컨테이너의 eth0

## 2.2.7.2 도커 네트워크 기능

> 컨테이너를 생성하면 기본적으로 `docker0 브리지`를 통해 외부와 통신할 수 있는 환경을 사용할 수 있지만 사용자의 선택에 따라 `여러 네트워크 드라이버`를 쓸 수도 있습니다. 도커가 자체적으로 제공하는 대표적인 네트워크 드라이버로는 `브리지(bridge), 호스트(host), 논(none), 컨테이너(container), 오버레이(overlay)`가 있습니다.
> 
> `서드파티 플러그인 솔루션`으로는 `weave, flannel, openvswitch` 등이 있으며, **더 확장된 네트워크 구성**을 위해 활용됩니다. 이번 장에서는 도커 자체만으로 손쉽게 쓸 수 있는 브리지, 호스트, 논, 컨테이너를 설명하겠습니다.

```docker
>> docker network ls
NETWORK ID     NAME      DRIVER    SCOPE
5bc3aae2ce99   bridge    bridge    local
422b9b59fe57   host      host      local
a51e3aa65a50   none      null      local
# 이미 브리지, 호스트, 논 네트워크가 있음을 알 수 있음. 브리지 네트워크는 컨테이너를
# 생성할 때 자동으로 연결되는 docker0 브리지를 활용하도록 설정돼 있습니다.
# 이 네트워크는 172.17.0.x IP 대역을 컨테이너에게 순차적으로 할당합니다.

>> docker network inspect bridge
[
    {
        "Name": "bridge",
        "Id": "5bc3aae2ce99b6f7c03d1ecdd558fb1d0c676671d9d9bb24068ffecf07240c80",
        "Created": "2025-01-21T09:47:11.210406792Z",
        "Scope": "local",
        "Driver": "bridge",
        "EnableIPv6": false,
        "IPAM": {
            "Driver": "default",
            "Options": null,
            "Config": [
                {
                    "Subnet": "172.17.0.0/16",
                    "Gateway": "172.17.0.1"
                }
            ]
        },
 ...
        "Containers": {},
 ...
 ]
 # docker network inspect 명령어로 서브넷과 게이트 웨이가 172.17.0.0/16과 
 # 172.17.0.1로 설정돼 있습니다. 또한 브리지 네트워크를 사용 중인 컨테이너 목록을
 # Containers 항목에서 확인할 수 있습니다
 
```

### 브리지 네트워크

> 이전 2.2.7.1절에서 설명한 docker0브리지와 비슷하게 `브리지 네트워크`는 docker0이 아닌 **사용자 정의 브리지를 새로 생성해 각 컨테이너에 연결하는 네트워크 구조**입니다. 컨테이너는 연결된 브리지를 통해 외부와 통신할 수 있습니다.

```docker
>> docker network create --driver bridge mybridge
# 브리지 타입의 네트워크를 생성하는 명령어
# 해당 브리지는 docker inspect 명령어로 알아보게 될 경우 172.18.0.0/16의 서브넷과
# 172.18.0.1의 내부 IP를 가진다는 것을 알 수 있다.

>> docker run -i -t --name mynetwork_container --net mybridge ubuntu:14.04
# 새로 정의한 브리지 타입의 네트워크를 사용하도록 컨테이너를 생성할 경우 해당 컨테이너는
# 내부 IP 주소로 172.18.0.2를 사용하게 된다.

>> docker network disconnect mybridge mynetwork_container
# 사용자 정의 네트워크에 해당 명령어로 컨테이너를 뗄 수 있다.
>> docker network connect mybridge mynetwork_container
# 사용자 정의 네트워크에 해당 명령어로 컨테이너를 붙일 수 있다.

# 단, 이번 장에서 설명하는 논, 호스트 네트워크 등과 같은 특별한 네트워크 모드에는 
# connect/disconnect 명령어를 사용할 수 없습니다.
# 브리지와 오버레이처럼 특정 IP 대역을 갖는 네트워크 모드에만 사용 가능합니다.

>> docker network create --driver=bridge \\
--subnet=172.72.0.0/16 \\
--ip-range=172.72.0.0/24 \\
--gateway=172.72.0.1 \\
my_custom_network
# 위와 같이 네트워크의 서브넷, 게이트웨이, IP 할당 범위 등을 임의로 설정할 수 있다.
```

### 호스트 네트워크

> 네트워크를 호스트로 설정하면 `호스트의 네트워크 환경`을 그대로 쓸 수 있습니다. 위의 브리지 드라이버 네트워크와 달리 호스트 드라이버의 네트워크는 별도로 생성할 필요 없이 기존의 host라는 이름의 네트워크를 사용합니다.

```docker
>> docker run -i -t --name network_host --net host ubuntu:14.04
# 네트워크를 host로 설정한 컨테이너의 내부에서 네트워크 환경을 확인하면 호스트와 같은 것
# 을 알 수 있습니다.

# 호스트 머신에서 설정한 호스트 이름도 컨테이너가 물려받기 때문에 컨테이너의 호스트
# 이름도 무작위 16진수가 아닌 도커 엔진이 설치된 호스트 머신의 호스트 이름으로 설정된다.

# 컨테이너의 네트워크를 호스트로 설정하면 컨테이너 내부의 애플리케이션을 별도의
# 포트 포워딩 없이 바로 서비스할 수 있습니다.
```

### 논 네트워크

> none은 말 그대로 `아무런 네트워크를 쓰지 않는 것`을 뜻합니다. 다음과 같이 컨테이너를 생성하면 외부와 연결이 단절됩니다.

```docker
>> docker run -i -t --name network_none --net none ubuntu:14.04
# --net 옵션으로 none을 설정한 컨테이너 내부에서 네트워크 인터페이스를 확인하면
# 로컬호스트를 나타내는 lo 외에는 존재하지 않는 것을 알 수 있습니다.
```

### 컨테이너 네트워크

> 컨테이너 네트워크를 사용하면 `다른 컨테이너의 네트워크 네임스페이스 환경`을 공유할 수 있습니다. 공유되는 속성은 내부 IP, 네트워크 인터페이스의 맥(MAC) 주소 등입니다.

```docker
>> docker run -i -t -d --name network_container_1 ubuntu:14.04

>> docker run -i -t -d --name network_container_2 \\
--net container:network_container_1 \\
ubuntu:14.04
```

### 브리지 네트워크와 --net-alias

> 브리지 타입의 네트워크와 run 명령어의 `--net-alias` 옵션을 함께 쓰면 특정 호스트 이름으로 컨테이너 여러 개에 접근할 수 있습니다. 위에서 생성한 mybridge 네트워크를 이용해 컨테이너를 3개 생성할 때, --net-alias 옵션의 값은 alicek106으로 설정했으며, 다른 컨테이너에서 alicek106이라는 호스트 이름으로 아래 3개의 컨테이너에 접근할 수 있습니다.

```docker
>> docker run -i -t -d --name network_alias_contianer_1 \\
--net mybridge \\
--net-alias alicek106 ubuntu:14.04

>> docker run -i -t -d --name network_alias_contianer_2 \\
--net mybridge \\
--net-alias alicek106 ubuntu:14.04

>> docker run -i -t -d --name network_alias_contianer_3 \\
--net mybridge \\
--net-alias alicek106 ubuntu:14.04

>> docker inspect network_alias_container_1 | grep IPAddress 
# Linux
OR
>> docker inspect network_alias_contianer_1 | findstr "IPAddress" 
# Windows
            "SecondaryIPAddresses": null,
            "IPAddress": "",
                    "IPAddress": "172.18.0.2",
# 첫 번쨰 컨테이너의 IP 주소가 172.18.0.2이므로 두 번째, 세 번째 컨테이너는
# 각각 172.18.0.3, 172.18.0.4일 것입니다. 세 개의 컨테이너에 접근할 컨테이너를
# 생성한 뒤 alicek106이라는 호스트 이름으로 ping 요청을 해보면 결과는 다음과 같습니다
>> docker run -i -t --name network_alias_ping --net mybridge ubuntu:14.04

root@a8dd0bfa0223:/# ping -c 1 alicek106
PING alicek106 (172.18.0.4) 56(84) bytes of data.
64 bytes from network_alias_contianer_3.mybridge (172.18.0.4): icmp_seq=1 ttl=64 time=0.041 ms

--- alicek106 ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 0ms
rtt min/avg/max/mdev = 0.041/0.041/0.041/0.000 ms
root@a8dd0bfa0223:/# ping -c 1 alicek106
PING alicek106 (172.18.0.3) 56(84) bytes of data.
64 bytes from network_alias_contianer_2.mybridge (172.18.0.3): icmp_seq=1 ttl=64 time=0.049 ms

--- alicek106 ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 0ms
rtt min/avg/max/mdev = 0.049/0.049/0.049/0.000 ms
root@a8dd0bfa0223:/# ping -c 1 alicek106
PING alicek106 (172.18.0.2) 56(84) bytes of data.
64 bytes from network_alias_contianer_1.mybridge (172.18.0.2): icmp_seq=1 ttl=64 time=0.026 ms

--- alicek106 ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 0ms
rtt min/avg/max/mdev = 0.026/0.026/0.026/0.000 ms
```

> 컨테이너 3개의 IP로 각각 ping이 전송된 것을 확인할 수 있습니다. 매번 달라지는 IP를 결정하는 것은 별도의 알고리즘이 아닌 `라운드로빈` 방식입니다. 이것이 가능한 이유는 `도커 엔진에 내장된 DNS`가 alicek106이라는 `호스트 이름`을 --net-alias 옵션으로 alicek106을 설정한 `컨테이너`로 변환하기 때문입니다.

![[image-2.17.png]]

> 도커의 `DNS`는 `호스트 이름으로 유동적인 컨테이너를 찾을 때` 주로 사용됩니다. 가장 대표적인 예가 `--link 옵션`인데, 이는 컨테이너의 IP가 변경돼도 별명으로 컨테이너를 찾을 수 있게 DNS에 의해 자동으로 관리됩니다. 단 이 경우는 `디폴트 브리지 네트워크의 컨테이너 DNS`라는 점이 다릅니다.

> 💡 GPT에 검색 결과 디폴트 브리지 네트워크의 경우, 컨테이너의 IP가 변경되어도 링크된 컨테이너의 별명으로 접근할 수 있는 것은 사실이다.
> 하지만 이는 DNS를 통한 연결이 아닌, 연결된 컨테이너의 이름이 /etc/hosts 파일에 정적으로 추가되기 때문에 가능한 것이라고 한다.
> 그래서 Docker의 내장 DNS 서버를 사용한다는 말은 틀렸다고 한다.

> `--net-alias 옵션` 또한 --link 옵션과 비슷한 원리로 작동합니다. 도커는 기본 브리지 네트워크가 아닌 `사용자가 정의한 브리지 네트워크에 사용되는 내장 DNS 서버`를 가지며, DNS의 IP는 127.0.0.11입니다. mybridge라는 이름의 네트워크에 속한 3개의 컨테이너는 run으로 생성할 때 --net-alias 옵션에 alicek106이라는 값을 입력했으며, 이 컨테이너의 IP는 DNS 서버에 alicek106이라는 호스트 이름으로 등록됩니다.

> mybridge 네트워크에 속한 컨테이너에서 alicek106이라는 호스트 이름으로 접근하면 DNS 서버는 라운드 로빈 방식을 이용해 컨테이너의 IP 리스트를 반환합니다. ping 명령어는 이 IP 리스트에서 첫 번째 IP를 사용하므로 매번 다른 IP로 ping을 전송합니다.

### MacVLAN 네트워크
> MacVLAN은 `호스트의 네트워크 인터페이스 카드를 가상화`해 물리 네트워크 환경을 컨테이너에게 `동일하게` 제공합니다.
> 따라서 MacVLAN을 사용하면 컨테이너는 물리 네트워크 상에서 `가상의 맥(MAC) 주소`를 가지며, 해당 네트워크에 연결된 `다른 장치와의 통신`이 가능해집니다.
> MacVLAN에 연결된 컨테이너는 기본적으로 할당되는 IP 대역인 172.17.X.X 대신 `네트워크 장비의 IP`를 할당받기 때문입니다.

> [!NOTE]
> 요약하자면 각 컨테이너는 물리 네트워크에서 가상 네트워크 인터페이스 카드를 받아서 고유의 Mac 주소와 IP 주소를 가지게 된다는 내용이다.
> 
> 해당 방식으로 컨테이너가 물리 네트워크에 직접 연결되면 아래의 장점을 가짐.
> - 물리 네트워크에 직접 연결되어 네트워크 인프라와의 호환성이 높아지는 점, 
> - 컨테이너 간 또는 컨테이너와 외부 네트워크 간의 통신에서 네트워크 성능을 Docker 브리지 네트워크를 거치지 않고 직접 물리 네트워크와 연결되므로 중간 단계가 생략된다는 점
> - 기존 Docker 브리지 네트워크와 분리되어 다른 컨테이너와 높은 수준의 격리를 제공한다는 점

![[image-2.18.png]]

> 위 그림과 같이 공유기, 라우터, 스위치와 같은 네트워크 장비에 두 대의 서버가 연결돼 있고, 각 서버는 192.168.0.0/24 대역에서 IP를 동적으로 할당받는다고 가정해 보겠습니다. 
> MacVLAN을 사용하면 각 컨테이너에 192.168.0.0/24 대역의 IP를 할당할 수 있습니다. 따라서 MacVLAN을 사용하는 컨테이너들과 동일한 IP 대역을 사용하는 서버 및 컨테이너들은 서로 통신이 가능합니다.

> [!NOTE]
> MacVLAN 네트워크를 사용하는 컨테이너는 기본적으로 호스트와 통신이 불가능합니다. 위 예시에서 컨테이너는 서버 2와는 통신할 수 있지만 서버 1과는 통신할 수 없습니다.
> 통신 차단이 되는 이유는 MacVLAN 모드에서 네트워크 트래픽이 호스트의 네트워크 스택을 우회하기 때문입니다. 
> 해당 방식으로 통신 차단을 통해 MacVLAN은 호스트와 컨테이너는 네트워크 레벨에서 격리를 유지합니다.

> MacVLAN을 사용하려면 적어도 1개의 네트워크 장비와 서버가 필요합니다. 그러나 대부분 환경에서 MacVLAN 네트워크의 사용 방법은 거의 동일하기 때문에 고가의 스위치와 서버 대신 공유기와 라즈베리 파이를 사용할 수도 있습니다. 상황이 여의치 않다면 가상 머신과 호스트 전용 어댑터로 테스트할 수도 있습니다.

```docker
# 여기서는 공유기에 유선으로 연결된 2대의 라즈베리 파이로 MacVLAN을 테스트했으며, 
# 네트워크 정보는 아래와 같습니다.

공유기의 네트워크 정보 : 192.168.0.0/24
서버 1 (node1) : 192.168.0.50
서버 2 (node2) : 192.168.0.51


# 두 서버에서 각각 명령어를 입력하면 MacVLAN 네트워크를 생성할 수 있습니다.
root@node1:~ # docker network create -d macvlan --subnet=192.168.0.0/24 \
> --ip-range=192.168.0.64/28 --gateway=192.168.0.1 \
> -o macvlan_mode=bridge -o parent=eth0 my_macvlan

root@node2:~ # docker network create -d macvlan --subnet=192.168.0.0/24 \
> --ip-range=192.168.0.128/28 --gateway=192.168.0.1 \
> -o macvlan_mode=bridge -o parent=eth0 my_macvlan
```
> 브리지 네트워크를 생성했을 때와 동일하게 docker network create 명령어를 사용했지만, 이번에는 여러 옵션이 함께 사용됐습니다. 각 옵션에 대한 설명은 아래와 같습니다.
> 
> -d : 네트워크 드라이버로 macvlan을 사용한다는 것을 명시합니다. --driver와 같습니다.
> 
> --subnet : 컨테이너가 사용할 네트워크 정보를 입력합니다. 여기서는 네트워크 장비의 IP 대역 기본 설정을 그대로 따릅니다.
> 
> --ip-range : MacVLAN을 생성하는 호스트에서 사용할 컨테이너의 IP 범위를 입력합니다. node1과 node2의 IP 범위가 겹쳐 동일한 IP의 컨테이너가 각각 생성된다면 컨테이너 네트워크가 정상적으로 동작하지 않을 수 있으므로 반드시 겹치지 않게 설정해야 합니다.
> 
> -o : 네트워크의 추가적인 옵션을 설정합니다. 위 예시에서는 macvlan_mode=bridge 값을 통해 MacVLAN을 bridge 모드로, parent=eth0 값을 통해 MacVLAN으로 생성될 컨테이너 네트워크 인터페이스의 부모 인터페이스를 eth0으로 지정합니다. eth0은 공유기에 랜선으로 연결되어 192.168.0.0/24 대역의 IP를 할당받은 네트워크 인터페이스입니다.

```docker
root@node1:~ # docker run -it --name c1 --hostname c1 \
> --network my_macvlan ubuntu:14.04

root@c1:/# ip a
# eth0@if2 NIC에 대해서 inet이 192.168.0.64/24임을 알 수 있다.

root@node2:~ # docker run -it --name c2 --hostname c2 \
> --network my_macvlan ubuntu:14.04

root@c2:/# ip a
# eth0@if2 NIC에 대해서 inet이 192.168.0.128/24임을 알 수 있다.

# 각 컨테이너에서 다른 서버나 컨테이너로 ping을 보내 네트워크가 정상 작동함을 알 수 있다.
```
> [!NOTE]
> MacVlan으로 nic를 가상으로 여러 개를 구축한다고 하면, 컨테이너끼리는 통신이 불가능하다.
> 하지만 이들끼리 통신이 가능하게 할려면 호스트를 경유해서 서로 통신이 가능하게 하는 방법이 존재한다.
> 또 다른 방법으로는 macvlan을 쓰지 않고 브리지 네트워크로 서로 통신이 가능하다. 하지만 이는 모든 컨테이너는 같은 ip를 사용하게 된다.

# 2.2.8 컨테이너 로깅
## 2.2.8.1 json-file 로그 사용하기

> 컨테이너 내부에서 어떤 일이 일어나는지 아는 것은 디버깅뿐만 아니라 운영 측면에서도 중요합니다. 애플리케이션 레벨에서 로그가 기록되도록 개발해 별도의 로깅 서비스를 쓸 수도 있지만, 도커는 컨테이너의 표준 출력(StdOut)과 에러(StdErr) 로그를 별도의 메타데이터 파일로 저장하며 이를 확인하는 명령어를 제공합니다.

> 먼저 컨테이너를 생성해 간단한 로그를 남겨 봅시다. 다음 명령은 mysql 8.0 버전의 컨테이너를 생성합니다.

```docker
# docker run -d --name mysql \
-e MYSQL_ROOT_PASSWORD=1234 \
mysql:8.0

mysql과 같은 애플리케이션을 구동하는 컨테이너는 포그라운드 모드로 실행되므로 -d 옵션을 써서 백그라운드 모드로 컨테이너를 실행하는 경우가 많습니다.

따라서 애플리케이션이 잘 구동되는지 여부를 알 수 없지만 docker logs 명령어를 써서 컨테이너의 표준 출력을 확인함으로써 애플리케이션의 상태를 알 수 있습니다. docker logs 명령어는 컨테이너 내부에서 출력을 보여주는 명령어입니다.

# docker logs mysql
2025-01-23 13:56:49+00:00 [Note] [Entrypoint]: Entrypoint script for MySQL Server 8.4.3-1.el9 started.
2025-01-23 13:56:49+00:00 [Note] [Entrypoint]: Switching to dedicated user 'mysql'
...
```

> 애플리케이션에 문제가 생겨 컨테이너가 켜지지 않았을 때 docker logs 명령어로 원인을 찾아볼 수도 있습니다.
> 먼저 이제 다른 방법으로 컨테이너를 생성해봅시다. 동일한 mysql 컨테이너를 생성하되, -e 옵션을 제외합니다.

```docker
# docker run -d --name no_password_mysql mysql:8.0

위 명령어를 실행한 뒤 docker ps 명령어로 컨테이너의 목록을 확인하면 no_passwd_mysql 컨테이너는 생성됐으나 실행되지 않았습니다. docker start 명령어로 다시 시작해도 컨테이너는 시작되지 않습니다.

# docker ps --format "table {{.ID}}\t{{.Status}}\t{{.Ports}}\t{{.Names}}"

# docker start no_password_mysql

# docker ps --format "table {{.ID}}\t{{.Status}}\t{{.Ports}}\t{{.Names}}"

이럴 때 docker logs 명령어를 사용하면 애플리케이션에 무슨 문제가 있는지 확인할 수 있습니다. 위의 경우는 mysql 실행에 필요한 환경변수를 지정하지 않아 컨테이너가 시작되지 않은 것입니다. 이처럼 컨테이너가 정상적으로 실행 및 동작하지 않고 docker attach 명령어도 사용하지 못하는 개발 환경에서 docker logs 명령어를 쓰면 간단하고 빠르게 에러를 확인할 수 있습니다.

# docker logs no_password_mysql
...
2025-01-23 15:20:51+00:00 [ERROR] [Entrypoint]: Database is uninitialized and password option is not specified
    You need to specify one of the following as an environment variable:
    - MYSQL_ROOT_PASSWORD
    - MYSQL_ALLOW_EMPTY_PASSWORD
    - MYSQL_RANDOM_ROOT_PASSWORD

컨테이너 로그가 너무 많아 읽기 힘들다면 --tail 옵션을 써서 마지막 로그 줄부터 출력할 줄의 수를 설정할 수 있습니다. 다음 예시에서는 컨테이너 로그 중 마지막 2줄만 출력합니다.

# docker logs --tail 2 mysql
    - MYSQL_ALLOW_EMPTY_PASSWORD
    - MYSQL_RANDOM_ROOT_PASSWORD

--since 옵션에 유닉스 시간을 입력해 특정 시간 이후의 로그를 확인할 수 있으며, -t 옵션으로 타임스탬프를 표시할 수도 있습니다. 컨테이너에서 실시간으로 출력되는 내용을 확인하려면 -f 옵션을 써서 로그를 스트림으로 확인할 수 있습니다.

# docker logs --since 1474765979 mysql

# docker logs -f -t mysql
```

> docker logs 명령어는 run 명령어에서 -i -t  옵션을 설정해 docker attach 명령어를 사용할 수 있는 컨테이너에도 쓸 수 있으며. 컨테이너 내부에서 bash 셸 등을 입출력한 내용을 확인할 수 있습니다.

```docker
# docker run -i -t --name logstest ubuntu:14.04
root@2233nnf7d7c6:/# echo test!
test!

# docker logs logstest
root@2233nnf7d7c6:/# echo test!
test!
```

> 기본적으로 위와 같은 컨테이너 로그는 JSON 형태로 도커 내부에 저장됩니다. 이 파일은 다음 경로에 컨테이너의 ID로 시작하는 파일명으로 저장됩니다. 아래의 log 명령으로 정제되지 않은 JSON 데이터를 볼 수 있습니다.

```powershell
cat /var/lib/docker/containers/${CONTAINER_ID}/${CONTAINER_ID}-json.log
```

> 그러나 컨테이너 내부의 출력이 너무 많은 상태로 방치하면 json 파일의 크기가 계속해서 커질 수 있고, 결국 호스트의 남은 저장 공간을 전부 사용할 수도 있습니다. 이러한 상황을 방지하기 위해서 --log-opt 옵션으로 컨테이너 json 로그 파일의 최대 크기를 지정할 수 있습니다. max-size는 로그 파일의 최대 크기, max-file은 로그 파일의 개수를 의미합니다. 

```docker
docker run -it \
--log-opt max-size=10k --log-opt max-fil=3 \
--name log_test ubuntu:14.04
```

> 어떠한 설정도 하지 않았다면 도커는 위와 같이 컨테이너 로그를 JSON 파일로 저장하지만 그 밖에도 각종 로깅 드라이버를 사용하게 설정해 컨테이너 로그를 수집할 수 있습니다. 사용 가능한 드라이버의 대표적인 예로 syslog, journald, fluentd, awslogs 등이 있으며 애플리케이션의 특징에 적합한 로깅 드라이버를 선택합니다. 

> [!NOTE]
> 로깅 드라이버는 기본적으로 json-file로 설정되지만 도커 데몬 시작 옵션에서 --log-driver 옵션을 써서 기본적으로 사용할 로깅 드라이버를 변경할 수 있습니다. 위에서 설명한 max-size와 같은 --log-opt 옵션 또한 도커 데몬에 적용함으로써 모든 컨테이너에 일괄적으로 사용할 수 있습니다. 
> - DOCKER_OPTS="--log-driver=syslog"
> - DOCKER_OPTS="--log-opt max-size=10k --log-opt max-file=3"

## 2.2.8.2 syslog 로그

> 컨테이너의 로그는 JSON뿐 아니라 syslog로 보내 저장하도록 설정할 수 있습니다. syslog는 유닉스 계열 운영체제에서 로그를 수집하는 오래된 표준 중 하나로서, 커널, 보안 등 시스템과 관련된 로그, 애플리케이션의 로그 등 다양한 종류의 로그를 수집해 저장합니다,

> `대부분의 유닉스 계열 체제에서는 syslog를 사용하는 인터페이스가 동일하기 때문에` 체계적으로 로그를 수집하고 분석할 수 있다는 장점이 있습니다.

```docker
다음 명령어를 입력해 syslog에 로그를 저장하는 컨테이너를 생성합니다.

# docker run -d --name syslog_container \
--log-driver=syslog \
ubuntu:14.04 \
echo syslogtest

syslog 로깅 드라이버는 기본적으로 로컬호스트의 syslog에 저장하므로 운영체제 및 배포판에 따라 syslog 파일의 위치를 알아야 확인할 수 있습니다.

# tail /var/log/syslog 
위의 위치는 우분투 14.04인 경우 syslog 파일의 위치이다.
```

> syslog를 원격 서버에 설치하면 로그 옵션을 추가해 `로그 정보를 원격 서버로` 보낼 수 있습니다. 이번에는 syslog를 `원격에 저장하는 방법`의 하나인 `rsyslog`를 써서 중앙 컨테이너로 로그를 저장해봅시다.

```docker
서버 호스트 IP : 192.168.0.100
클라이언트 IP : 192.168.0.101

서버 호스트에 rsyslog 서비스가 시작하도록 설정된 컨테이너를 구동하고 클라이언트 호스트에서 컨테이너를 생성해 서버의 rsyslog 컨테이너에 로그를 저장합니다. 서버 호스트에서 다음 명령어를 입력해 rsyslog 컨테이너를 생성합니다.

server@192.168.0.100# docker run -i -t \
-h rsyslog \
--name rsyslog_container \
-p 514:514 -p 514:514/udp \
ubuntu:14.04

-p 514:514는 tcp 514포트를 외부에 노출한다는 의미이고, -p 514:514/udp는 udp 514포트를 외부에 노출한다는 의미입니다.
컨테이너 내부의 rsyslog.conf 파일을 열어 syslog 서버를 구동시키는 항목의 주석을 해제한 후 변경사항을 저장합니다.

root@rsyslog:/# vi /etc/rsyslog.conf
...
# provides UDP syslog reception
$ModLoad imudp
$UDPServerRun 514

# provide TCP syslog reception
$ModLoad imtcp
$InputTCPServerRun 514
...

다음 명령어를 입력해 rsyslog 서비스를 재시작합니다.

root@rsyslog:/# service rsyslog restart
```
> [!NOTE]
> rsyslog는 컨테이너가 아닌 우분투, CentOS 등의 호스트에서도 쓸 수 있으며, 위 방법은 우분투를 기준으로 합니다. 그러나 컨테이너를 쓰면 호스트가 어떤 운영체제이든 상관없이 rsyslog를 사용할 수 있습니다. 
```docker
컨테이너를 빠져 나온 뒤 클라이언트 호스트에서 아래의 명령어를 입력해 컨테이너를 생성합니다. 컨테이너 로그를 기록하기 위해 간단한 echo 명령어를 실행합니다.

client@192.168.0.101# docker run -i -t \
--log-driver=syslog \
--log-opt syslog-address=tcp://192.168.0.100:514 \
--log-opt tag="mylog" \
ubuntu:14.04

root@64513d11e91d:/# echo test
test

--log-opt는 로깅 드라이버에 추가할 옵션을 뜻하고,syslog-address는 rsyslog 컨테이너에 접근할 수 있는 주소를 입력합니다. tag는 로그 데이터가 기록될 떄 함꼐 저장될 태그이며 로그를 분류하기 위해 사용합니다.

--log-opt 옵션으로 syslog-facility를 쓰면 로그가 저장될 파일을 바꿀 수 있습니다. facility는 로그를 생성하는 주체에 따라 로그를 다르게 저장하는 것으로, 여러 애플리케이션에서 수집되는 로그를 분류하는 방법입니다. 기본적으로 daemon으로 설정돼 있지만 kern, user, mail 등 다른 facility를 사용할 수 있습니다.

# docker run -i -t \
--log-driver=syslog \
--log-opt syslog-address=tcp://192.168.0.100:514 \
--log-opt tag="maillog" \
--log-opt syslog-facility="mail" \
ubuntu:14.04
```
> [!NOTE]
> rsyslog는 우분투에서 쓸 수 있는 기본적인 로깅 방법이므로 별도의 UI를 제공하지 않지만 `Logentries`, `LogAnalyzer` 등과 같은 로그 분석기와 연동하면 웹 인터페이스를 활용해 편리하게 로그를 확인할 수 있습니다.

## 2.2.8.3 fluentd 로깅
> `fluentd`는 각 종 로그를 수집하고 저장할 수 있는 기능을 제공하는 `오픈소스 도구`로서, 도커 엔진의 컨테이너의 로그를 fluentd를 통해 저장할 수 있도록 플러그인을 공식적으로 제공합니다. fluentd는 데이터 포맷으로 `JSON`을 사용하기 때문에 쉽게 사용할 수 있을 뿐만 아니라 수집되는 데이터를 AWS S3, HDFS(Hadoop Distributed File System), MongoDB 등 `다양한 저장소에 저장할 수 있다는 장점`이 있습니다.
> 
> 여기서 살펴볼 예제는 fluentd와 MongoDB를 연동해 데이터를 저장하는 방법을 보여줍니다. 특정 호스트에 생성되는 컨테이너는 하나의 fluentd에 접근하고, fluentd는 MongoDB에 데이터를 저장하는 구조입니다.

![[image-2.19.jpg]]

>[!NOTE]
>그림 2.19는 fluentd를 통해 로그가 수집되는 흐름을 보여줍니다. 위 그림대로라면 도커 서버, fluentd 서버, MongoDB 서버로 구성되므로 서버는 최소 3대가 필요하지만 사용자의 환경에 맞게 변경해서 사용하면 됩니다. 예를 들어, 각 서버 호스트에 fluentd를 설치할 수도 있고, 테스트를 위 MongoDB 서버, fluentd 서버, 도커 서버가 하나의 물리 머신에서 동작하도록 구성할 수도 있습니다. 글쓴이는 하나의 물리머신에서 3대의 컨테이너로 실행할 예정입니다.

```docker

root@mongo:/ docker run --name mongoDB -d \
-p 27017:27017 \
mongo

fluentd 서버의 호스트에서 다음과 같은 내용을 fluentd.conf 파일로 저장합니다. fluentd.conf 파일의 주 내용은 들어오는 로그 데이터를 몽고 DB에 전송하고, access라는 이름의 컬렉션에 로그를 저장하며, 몽고 DB 컨테이너의 호스트 주소와 포트 번호를 지정한 것입니다. <match docker.**>는 로그의 태그가 docker로 시작하면 이를 MongoDB에 전달하는 것을 의미합니다.
```

```fluentd.conf
<source>
	@type forward
</source>

<match docker.**>
	@type mongo
	database nginx
	collection access
	host (localhost)
	port 27017
	flush_interval 10s
</match>

만약 MongoDB에 사용자와 비밀번호를 통한 인증 작업을 설정하지 않았지만 MongoDB에 인증 정보를 설정했다면 위 내용 중 flush_interval 10s 항목 밑에 user, password를 정의하고 사용자명과 비밀번호를 명시해야 합니다.
```

```docker
root@fluentd:/# docker run -d --name fluentd -p 24224:24224 \
-v $(pwd)/fluentd.conf:/fluentd/etc/fluentd.conf \
-e FLUENTD_CONF=fluentd.conf \
alicek106/fluentd:mongo

fluentd.conf 파일이 저장된 디렉터리에서 다음 명령어를 입력해 fluentd 컨테이너를 생성합니다. 위 내용의 fluentd.conf 파일을 -v 옵션을 이용해 fluentd 컨테이너에 공유하고 설정 파일로 사용합니다.
```
>[!NOTE] 
>도커 허브의 fluentd 이미지에는 몽고 DB에 연결하는 플러그인이 내장돼 있지 않습니다. alicek106/fluentd:mongo 이미지는 공식 fluentd 이미지에 몽고 DB 플러그인을 설치한 것입니다.

```docker
root@docker-server:/ docker run -p 80:80 -d \
--log-driver=fluentd \
--log-opt fluentd-address=(localhost):24224 \
--log-opt tag=docker.nginx.webserver \
nginx

도커 서버에서 로그를 수집할 컨테이너를 생성합니다. 이 때 --log-driver를 fluentd로 설정하고 --log-opt의 fluentd-address 값에 fluentd 서버 주소를 지정합니다. --log opt tag를 명시함으로써 로그의 태그를 docker.nginx.webserver로 지정했지만 fluentd의 설정 파일 중 <match docker.**>에 맞으므로 MongoDB에 로그로서 저장됩니다.

이미지는 어떤 것이든 상관없지만 로그가 기록되는 것을 확실히 알 수 있게 nginx 이미지를 사용해 컨테이너를 생성해 봅시다.
(이미지는 어떤 것이든 상관없지만 로그가 기록되는 것을 확실히 알 수 있게 nginx 이미지를 사용했습니다.)
```

```docker
위의 docker run 명령어는 호스트의 80번 포트로 nginx 웹 서버에 접근할 수 있습니다 웹 서버에 접근해야 컨테이너 내부에서 접근 로그가 출력되므로 한 번 이상은 웹 서버에 접근해야 합니다. 따라서 웹 브라우저 등을 통해 위에서 생성한 nginx 서버에 접근한 뒤 MongoDB 서버에서 MongoDB 컨테이너에 들어가 데이터를 확인하면 nginx 웹 서버에 대한 접근 기록이 저장된 것을확인할 수 있습니다.

root@mongo:/ docker exec -it mongoDB mongoDB mongo
MongoDB shell version v3.4.0
...
>show dbs
admin 0.00GB
local 0.00GB
nginx 0.00GB

>use nginx
switched to db nginx

>show collections
access

>db['access'].find()

여기서 기억해야 할 것은 도커 엔진은 fluentd 서버에 컨테이너의 로그를 전송했고, 이 로그는 다시 MongoDB 서버로 전송되어 저장됐다는 점입니다.
```


## 2.2.8.4 아마존 클라우드워치 로그

> AWS(Amazon Web Service)에서는 로그 및 이벤트 등을 수집하고 저장해 시각적으로 보여주는 클라우드워치(CloudWatch)를 제공합니다. 도커를 AWS EC2에서 사용하고 있다면 다른 도구를 별도로 설치할 필요 없이 컨테이너에서 드라이버 옵션을 설정하는 것만으로 클라우드워치 로깅 드라이버를 사용할 수 있습니다.
> 
> 클라우드워치를 사용하는 것은 아래의 단계를 따릅니다.
> - 클라우드워치에 해당하는 IAM 권한 생성
> - 로그 그룹 생성
> - 로그 그룹에 로그 스트림(LogStream) 생성
> - 클라우드워치의 IAM 권한을 사용할 수 있는 EC2 인스턴스 생성과 로그 전송

>[!NOTE]
>AWS Elastic Beanstalk는 AWS에서 제공하는 완전 관리형 서비스로, 해당 서비스의 로깅 시스템이 AWS CloudWatch Logs에 해당한다.

#### 설정 순서
1. 클라우드워치에 해당하는 IAM 권한 생성(권한 정책으로 CloudWatchFullAccess를 연결해야 함)
2. 로그 그룹 생성
3. 로그 그룹에 로그 스트림 생성
4. 클라우드워치의 IAM 권한을 사용할 수 있는 EC2 인스턴스 생성과 로그 전송
	1. 인스턴스가 생성됐다면 해당 서버에 접속해 도커 엔진을 설치한 뒤 클라우드워치를 로깅 드라이버로 사용할 수 있습니다. 
	2. IAM 권한을 사용하도록 설정한 EC2 인스턴스의 도커 엔진에서 다음 명령어를 입력해 컨테이너를 생성합니다.
	
```docker
# docker run -i -t \
--log-driver=awslogs \
--log-opt awslog-region=ap-northeast-2 \
--log-opt awslog-group=mylogs \
--log-opt awslogs-stream=mylogstream \
ubuntu:14.04
```

>[!NOTE]
>기존에 미리 생성해 둔 인스턴스가 있다면 IAM 권한 설정을 위해 추가 생성하지 않고 [IAM 역할] 항목에서 바꾸면 된다.

# 2.2.9 컨테이너 자원 할당 제한

> 컨테이너를 생성하는 run, create 명령어에서 `컨테이너의 자원 할당량을 조정하도록 옵션을 입력`할 수 있습니다. 아무런 옵션을 입력하지 않으면 컨테이너는 `호스트의 자원을 제한 없이` 쓸 수 있게 설정되므로 제품 단계의 컨테이너를 고려한다면 컨테이너의 자원 할당을 제한해 호스트와 다른 컨테이너의 동작을 방해하지 않게 설정하는 것이 좋습니다.

> 현재 컨테이너에 설정된 자원 제한을 확인하는 가장 쉬운 방법은 `docker inspect` 명령어를 입력하는 것입니다. 지금까지 테스트한 컨테이너 중 하나를 선택해 inspect 명령어를 입력하면 상세한 정보를 확인할 수 있습니다.

```docker
# docker inspect rsyslog
"HostConfig": {
...
			"DiskQuota":0,
			"KernelMemory":0,
			"MemoryReservation":0,
			"MemorySwap":0,
			"MemorySwappiness":-1,
			"OomKillDisable":false,
			"PidsLimit":0,
			"Ulimits":null,
			"CpuCount":0,
			"CpuPercent":0,
			"IOMaximumIOps":0,
			"IOMaximumBandwidth":0,
...

자원 할당을 제한하기 위해 컨테이너에 적용할 수 있는 옵션은 만지만 여기서는 대표적인 몇 가지만 설명하겠습니다.
```

>[!NOTE]
>run 명령어에서 설정된 컨테이너의 자원 제한을 변경하려면 update 명령어를 사용합니다. `docker update (변경할 자원 제한) (컨테이너 이름)`

## 2.2.9.1 컨테이너 메모리 제한

> docker run 명령어에 --memory를 지정해 컨테이너의 메모리를 제한할 수 있습니다. 입력할 수 있는 단위는 m(megabyte), g(gigabyte)이며 제한할 수 있는 최소 메모리는 4MB입니다. 다음 명령어는 컨테이너의 메모리 사용량을 1GB로 제한합니다.

```docker
# docker run -d \
--memory="1g" \
--name memory_1g \
nginx

위 명령어로 컨테이너를 생성한 뒤 inspect 명령어로 메모리 값을 확인해보면 1GB에 해당하는 바이트 값이 설정됐음을 알 수 있음

# docker inspect memory_1g | grep \"Memory\"

컨테이너 내에서 동작하는 프로세스가 컨테이너에 할당된 메모리를 초과하면 컨테이너는 자동으로 종료되므로 애플리케이션에 따라 메모리를 적절하게 할당하는 것이 좋습니다. 다음 명령어는 메모리를 매우 적게 할당하는 경우로서 4MB의 메모리로 mysql 컨테이너를 실행하면 메모리가 부족해서 컨테이너가 실행되지 않습니다.

# docker run -d --name memory_4m \
--memory="4m" \
mysql

# docker ps -a --format "table {{.ID}}\t{{.Status}}\t{{.Names}}"

기본적으로 컨테이너의 Swap 메모리는 메모리의 2배로 설정되지만 별도로 지정할 수 있습니다. 다음 명령어는 Swap 메모리를 500MB로, 메모리를 200MB로 설정해 컨테이너를 생성합니다.

# docker run -it --name swap_500m \
--memory=200m \
--memory-swap=500m \
ubuntu:14.04
```

>[!NOTE]
>Docker에서 말하는 컨테이너의 `swap 메모리`는 컨테이너가 사용하는 물리 메모리(RAM)외에, 시스템의 `디스크 공간을 이용해` 가상 메모리처럼 사용하는 부분을 말해요.
>컨테이너가 할당된 RAM을 모두 사용하고 나면, `더 이상의 메모리를 필요로 할 경우` 디스크 공간을 사용해서 메모리를 보완할 수 있는데, 이때 사용하는 것이 swap이에요. 이를 통해 컨테이너가 메모리 부족 상태에 빠지지 않고 계속해서 작동할 수 있지만, swap 메모리는 `디스크 기반`이기 때문에 RAM보다 훨씬 느려서 `성능 저하가 발생`할 수 있습니다.

